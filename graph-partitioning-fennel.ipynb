{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded...\n",
      "Nodes: 1000\n",
      "Edges: 2939\n",
      "Graph is undirected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shared\n",
    "import networkx as nx\n",
    "\n",
    "pwd = %pwd\n",
    "\n",
    "DATA_FILENAME = os.path.join(pwd, \"data\", \"oneshot_fennel_weights.txt\")\n",
    "OUTPUT_DIRECTORY = os.path.join(pwd, \"output\")\n",
    "\n",
    "# Read input file for prediction model, if not provided a prediction\n",
    "# model is made using FENNEL\n",
    "PREDICTION_MODEL = \"\"\n",
    "\n",
    "# File containing simulated arrivals. This is used in simulating nodes\n",
    "# arriving at the shelter. Nodes represented by line number; value of\n",
    "# 1 represents a node as arrived; value of 0 represents the node as not\n",
    "# arrived or needing a shelter.\n",
    "#SIMULATED_ARRIVAL_FILE = os.path.join(pwd, \"data\", \"simulated_arrival.txt\")\n",
    "SIMULATED_ARRIVAL_FILE = \"\"\n",
    "\n",
    "# Number of shelters\n",
    "num_partitions = 4\n",
    "\n",
    "# The number of iterations when making prediction model\n",
    "num_iterations = 10\n",
    "\n",
    "# Percentage of prediction model to use before discarding\n",
    "# When set to 0, prediction model is discarded, useful for one-shot\n",
    "prediction_model_cut_off = 0.10\n",
    "\n",
    "# Alpha value used in one-shot (when restream_batches set to 1)\n",
    "one_shot_alpha = 0.5\n",
    "\n",
    "# Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "# When set to 1, one-shot is used with alpha value from above\n",
    "restream_batches = 10\n",
    "\n",
    "# Create virtual nodes based on prediction model\n",
    "use_virtual_nodes = False\n",
    "\n",
    "# Virtual nodes: node weight and edge weight\n",
    "virtual_edge_weight = 1.0\n",
    "\n",
    "# If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "# otherwise the node is removed from the graph. Also enables the edge calculation\n",
    "# function.\n",
    "graph_modification_functions = False\n",
    "\n",
    "# read METIS file\n",
    "G = shared.read_metis(DATA_FILENAME)\n",
    "\n",
    "# Alpha value used in prediction model\n",
    "prediction_model_alpha = G.number_of_edges() * (num_partitions / G.number_of_nodes()**2)\n",
    "\n",
    "# Order of nodes arriving\n",
    "arrival_order = list(range(0, G.number_of_nodes()))\n",
    "#random.shuffle(arrival_order)\n",
    "\n",
    "if SIMULATED_ARRIVAL_FILE == \"\":\n",
    "    # mark all nodes as needing a shelter\n",
    "    simulated_arrival_list = [1]*G.number_of_nodes()\n",
    "else:\n",
    "    with open(SIMULATED_ARRIVAL_FILE, \"r\") as f:\n",
    "        simulated_arrival_list = [int(line.rstrip('\\n')) for line in f]\n",
    "\n",
    "print(\"Graph loaded...\")\n",
    "print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "print(\"Edges: {}\".format(G.number_of_edges()))\n",
    "if nx.is_directed(G):\n",
    "    print(\"Graph is directed\")\n",
    "else:\n",
    "    print(\"Graph is undirected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION MODEL\n",
      "----------------\n",
      "\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\n",
      "0.00000\t\t0.1224906431\t360\n",
      "\n",
      "Assignments:\n",
      "[ 0  1  2  0  1  0  1  3  0  0  2  0  0  1  0  2  3  2  2  0  0  3  2  3  0  1  3  1  2  0  0  2  0  1  2  3  0  3  2  1  2  0  2  1  0  3  1  3  3  2  0  1  2  0  0  2  3  0  1  0  2  1  3  1  1  1  1  2  3  2  1  0  0  1  0  3  1  1  0  1  2  3  1  0  1  2  1  2  3  0  1  3  3  0  1  2  3  0  0  1  1  2  3  1  1  0  1  0  2  0  2  1  2  2  3  1  3  1  0  2  1  0  0  3  1  1  3  2  2  3  0  0  1  0  0  3  1  2  3  1  1  2  3  2  3  2  1  2  0  0  3  1  1  2  1  2  1  3  3  0  1  3  0  3  0  2  3  2  3  1  0  1  0  1  2  1  0  2  1  1  2  0  0  0  1  0  2  1  1  2  3  2  2  0  0  3  1  2  3  0  2  1  0  3  2  2  2  1  2  2  1  0  3  0  3  0  0  1  2  3  0  3  1  0  2  2  2  2  1  2  3  3  1  1  3  3  2  1  0  3  2  2  2  3  3  2  2  1  1  3  0  2  0  3  3  0  1  2  1  1  3  1  0  2  3  1  3  2  3  3  1  0  2  3  0  1  0  1  2  3  2  3  1  2  0  3  2  0  0  1  1  3  2  0  0  3  3  1  3  0  1  2  3  0  3  1  1  0  3  1  2  2  0  2  2  2  3  0  2  3  0  3  0  0  2  3  2  1  1  2  2  1  2  0  0  1  3  3  2  3  2  0  2  3  3  2  0  1  3  3  1  2  1  3  3  1  1  2  3  0  1  3  2  3  1  1  0  1  3  0  1  3  0  2  2  2  3  2  2  3  0  2  2  3  1  3  2  3  3  1  0  2  3  0  2  2  2  0  3  3  1  1  0  0  0  3  0  3  2  3  0  3  1  2  3  0  0  2  1  3  1  0  3  3  1  0  0  3  1  3  2  1  1  2  3  2  3  1  3  1  3  0  2  3  0  1  1  0  3  2  3  3  2  2  2  1  2  2  1  3  0  2  1  0  2  2  0  3  1  0  3  1  1  2  1  1  3  3  2  2  0  1  1  3  0  0  0  1  0  1  2  1  0  3  0  2  1  2  3  2  0  2  3  2  3  0  0  0  1  1  3  2  0  3  3  2  0  1  0  1  3  1  1  3  2  3  2  1  3  0  1  2  2  1  0  3  0  3  1  0  3  2  3  3  2  2  0  1  3  2  0  3  3  2  1  1  0  0  0  2  1  1  3  0  3  1  3  2  1  2  2  2  0  1  0  1  2  0  1  0  1  2  0  2  3  3  2  1  2  0  2  2  1  2  2  0  0  0  1  0  3  3  1  3  1  3  3  1  2  0  0  1  0  0  0  2  1  1  1  1  0  0  2  3  2  3  0  2  2  3  1  3  3  3  3  3  2  1  0  3  0  3  3  0  0  1  0  2  2  1  3  2  1  0  1  3  1  2  2  3  1  2  3  0  0  2  2  0  1  1  2  1  3  0  3  1  3  3  3  3  3  1  2  3  0  0  3  2  2  3  3  3  2  3  2  0  0  1  0  1  0  2  0  3  3  0  1  0  3  0  3  2  3  0  3  0  0  1  0  3  2  2  3  3  0  0  0  3  2  0  0  0  3  1  0  2  2  2  2  3  1  2  2  3  1  0  2  0  2  3  1  2  1  2  1  0  0  0  1  3  0  0  3  2  3  0  2  1  3  3  2  1  1  3  3  2  1  1  1  1  0  1  0  3  1  1  3  0  2  1  3  2  0  3  3  1  1  1  0  3  1  3  3  3  2  2  2  2  0  2  2  2  3  1  1  2  3  0  1  0  3  0  0  0  2  1  0  3  1  2  2  3  1  3  2  3  2  3  1  0  1  1  0  2  3  0  0  0  3  2  3  1  0  1  2  2  3  0  3  2  0  0  0  1  1  1  0  1  1  3  1  3  0  1  2  1  1  2  0  0  3  3  2  3  3  0  2  3  2  0  1  0  2  0  0  3  1  2  1  0  2  2  0  0  0  1  3  2  2  1  1  1  0  1  0  3  0  3  2  0  3  1  1  1  3  2  3  3  2  0  1  1  2  1  1  1  0  0  1  2  1  2  3  3  1  3  0  3  1  3  0  2  2  2  0  2  0  2  0  0  3  3  2  2  1  1  1  2  1  2  0  2  2  3  1  1  1  3  3  2  2  2  0  3  2  1  3  2  0  1  0  0  0  0  3  0  2  3  1  1]\n",
      "\n",
      "Fixed: 0\n",
      "\n",
      "Partitions - nodes (weight):\n",
      "P0: 250.0 (250)\n",
      "P1: 250.0 (250)\n",
      "P2: 250.0 (250)\n",
      "P3: 250.0 (250)\n"
     ]
    }
   ],
   "source": [
    "import pyximport; pyximport.install()\n",
    "import fennel\n",
    "import numpy as np\n",
    "\n",
    "UNMAPPED = -1\n",
    "\n",
    "# reset\n",
    "assignments = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "fixed = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "\n",
    "print(\"PREDICTION MODEL\")\n",
    "print(\"----------------\\n\")\n",
    "\n",
    "if PREDICTION_MODEL:\n",
    "    with open(PREDICTION_MODEL, \"r\") as inf:\n",
    "        assignments = np.fromiter(inf.readlines(), dtype=np.int32)\n",
    "\n",
    "else:\n",
    "    assignments = fennel.generate_prediction_model(G, num_iterations, num_partitions, assignments, fixed, prediction_model_alpha)\n",
    "\n",
    "x = shared.score(G, assignments)\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\")\n",
    "print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\".format(x[0], x[1], x[2]))\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_virtual_nodes:\n",
    "    print(\"Creating virtual nodes and assigning edges based on prediction model\")\n",
    "\n",
    "    # create virtual nodes\n",
    "    virtual_nodes = list(range(G.number_of_nodes(), G.number_of_nodes() + num_partitions))\n",
    "    print(\"\\nVirtual nodes:\")\n",
    "\n",
    "    # create virtual edges\n",
    "    virtual_edges = []\n",
    "    for n in range(0, G.number_of_nodes()):\n",
    "        virtual_edges += [(n, virtual_nodes[assignments[n]])]\n",
    "\n",
    "    # extend assignments\n",
    "    assignments = np.append(assignments, np.array(list(range(0, num_partitions)), dtype=np.int32))\n",
    "    fixed = np.append(fixed, np.array([1] * num_partitions, dtype=np.int32))\n",
    "\n",
    "    G.add_nodes_from(virtual_nodes, weight=1)\n",
    "    G.add_edges_from(virtual_edges, weight=virtual_edge_weight)\n",
    "\n",
    "    print(\"\\nAssignments:\")\n",
    "    shared.fixed_width_print(assignments)\n",
    "    print(\"Last {} nodes are virtual nodes.\".format(num_partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign first 100 arrivals using prediction model, then discard\n",
      "\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\n",
      "0.00300\t\tnan\t0\n",
      "0.00200\t\tnan\t0\n",
      "0.00100\t\tnan\t0\n",
      "0.00400\t\tnan\t0\n",
      "0.00300\t\tnan\t0\n",
      "0.00600\t\tnan\t0\n",
      "0.00500\t\tnan\t0\n",
      "0.00400\t\tnan\t0\n",
      "0.00700\t\tnan\t0\n",
      "0.01000\t\tnan\t0\n",
      "0.00900\t\tnan\t0\n",
      "0.01200\t\tnan\t0\n",
      "0.01500\t\tnan\t0\n",
      "0.01400\t\tnan\t0\n",
      "0.01700\t\t0.0000000000\t0\n",
      "0.01600\t\t0.0000000000\t0\n",
      "0.01500\t\t0.0000000000\t0\n",
      "0.01400\t\t0.0000000000\t0\n",
      "0.01300\t\t0.0000000000\t0\n",
      "0.01600\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.01800\t\t0.0000000000\t0\n",
      "0.01700\t\t0.0000000000\t0\n",
      "0.01600\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.01800\t\t0.0000000000\t0\n",
      "0.01700\t\t0.0000000000\t0\n",
      "0.01600\t\t0.0000000000\t0\n",
      "0.01500\t\t0.0000000000\t0\n",
      "0.01800\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.01800\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02500\t\t0.0000000000\t0\n",
      "0.02400\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02600\t\t0.0000000000\t0\n",
      "0.02500\t\t0.0000000000\t0\n",
      "0.02800\t\t0.0000000000\t0\n",
      "0.02700\t\t0.0000000000\t0\n",
      "0.02600\t\t0.0000000000\t0\n",
      "0.02500\t\t0.0000000000\t0\n",
      "0.02400\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.01800\t\t0.0000000000\t0\n",
      "0.01700\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02500\t\t0.0000000000\t0\n",
      "0.02400\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02500\t\t0.0000000000\t0\n",
      "0.02400\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02400\t\t0.0000000000\t0\n",
      "0.02300\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02100\t\t0.0000000000\t0\n",
      "0.02000\t\t0.0000000000\t0\n",
      "0.01900\t\t0.0000000000\t0\n",
      "0.02200\t\t0.0000000000\t0\n",
      "0.02500\t\t0.0000000000\t0\n",
      "0.02400\t\t0.0000000000\t0\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\n",
      "0.02400\t\t0.1861177271\t547\n",
      "\n",
      "Assignments:\n",
      "[ 0  1  2  0  1  0  1  3  0  0  2  0  0  1  0  2  3  2  2  0  0  3  2  3  0  1  3  1  2  0  0  2  0  1  2  3  0  3  2  1  2  0  2  1  0  3  1  3  3  2  0  1  2  0  0  2  3  0  1  0  2  1  3  1  1  1  1  2  3  2  1  0  0  1  0  3  1  1  0  1  2  3  1  0  1  2  1  2  3  0  1  3  3  0  1  2  3  0  0  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "\n",
      "Fixed: 100\n",
      "\n",
      "Partitions - nodes:\n",
      "P0: 31\n",
      "P1: 28\n",
      "P2: 22\n",
      "P3: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sami/repos/smbwebs/graph-partitioning/shared.py:118: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  cut_ratio = mismatch / len(graph.edges())\n"
     ]
    }
   ],
   "source": [
    "cut_off_value = int(prediction_model_cut_off * G.number_of_nodes())\n",
    "if prediction_model_cut_off == 0:\n",
    "    print(\"Discarding prediction model\\n\")\n",
    "else:\n",
    "    print(\"Assign first {} arrivals using prediction model, then discard\\n\".format(cut_off_value))\n",
    "\n",
    "# fix arrivals\n",
    "nodes_arrived = []\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\")\n",
    "for a in arrival_order:\n",
    "    # check if node needs a shelter\n",
    "    if simulated_arrival_list[a] == 0:\n",
    "        continue\n",
    "\n",
    "    nodes_fixed = len([o for o in fixed if o == 1])\n",
    "    if nodes_fixed >= cut_off_value:\n",
    "        break\n",
    "    fixed[a] = 1\n",
    "    nodes_arrived.append(a)\n",
    "\n",
    "    # make a subgraph of all arrived nodes\n",
    "    Gsub = G.subgraph(nodes_arrived)\n",
    "\n",
    "    x = shared.score(Gsub, assignments, num_partitions)\n",
    "    print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\".format(x[0], x[1], x[2]))\n",
    "\n",
    "# remove nodes not fixed, ie. discard prediction model\n",
    "for i in range(0, len(assignments)):\n",
    "    if fixed[i] == -1:\n",
    "        assignments[i] = -1\n",
    "\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\")\n",
    "x = shared.score(G, assignments, num_partitions)\n",
    "print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\".format(x[0], x[1], x[2]))\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning in batches of 10\n",
      "--------------------------------\n",
      "\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\tALPHA\n",
      "0.01800\t\t0.0000000000\t0\t\t0.0102479339\n",
      "0.02000\t\t0.0263157895\t1\t\t0.0105555556\n",
      "0.01800\t\t0.0232558140\t1\t\t0.0101775148\n",
      "0.01600\t\t0.0196078431\t1\t\t0.0104081633\n",
      "0.01800\t\t0.0303030303\t2\t\t0.0117333333\n",
      "0.02400\t\t0.0259740260\t2\t\t0.0120312500\n",
      "0.01800\t\t0.0348837209\t3\t\t0.0119031142\n",
      "0.02400\t\t0.0500000000\t5\t\t0.0123456790\n",
      "0.02600\t\t0.0614035088\t7\t\t0.0126315789\n",
      "0.02400\t\t0.0737704918\t9\t\t0.0122000000\n",
      "0.02200\t\t0.0724637681\t10\t\t0.0125170068\n",
      "0.02800\t\t0.0784313725\t12\t\t0.0126446281\n",
      "0.02200\t\t0.0807453416\t13\t\t0.0121739130\n",
      "0.02400\t\t0.0818713450\t14\t\t0.0118750000\n",
      "0.02200\t\t0.0833333333\t15\t\t0.0115200000\n",
      "0.02000\t\t0.0932642487\t18\t\t0.0114201183\n",
      "0.01400\t\t0.0931372549\t19\t\t0.0111934156\n",
      "0.02000\t\t0.0941704036\t21\t\t0.0113775510\n",
      "0.01800\t\t0.1193415638\t29\t\t0.0115576694\n",
      "0.01600\t\t0.1167315175\t30\t\t0.0114222222\n",
      "0.02600\t\t0.1127272727\t31\t\t0.0114464100\n",
      "0.02000\t\t0.1056105611\t32\t\t0.0118359375\n",
      "0.01400\t\t0.0993788820\t32\t\t0.0118273646\n",
      "0.00800\t\t0.0949554896\t32\t\t0.0116608997\n",
      "0.01000\t\t0.0991735537\t36\t\t0.0118530612\n",
      "0.01200\t\t0.0979381443\t38\t\t0.0119753086\n",
      "0.01800\t\t0.0938271605\t38\t\t0.0118334551\n",
      "0.01200\t\t0.0883720930\t38\t\t0.0119113573\n",
      "0.01000\t\t0.0881057269\t40\t\t0.0119395135\n",
      "0.01600\t\t0.0878661088\t42\t\t0.0119500000\n",
      "0.01800\t\t0.0884086444\t45\t\t0.0121118382\n",
      "0.02400\t\t0.0828729282\t45\t\t0.0123129252\n",
      "0.02600\t\t0.0858143608\t49\t\t0.0123526230\n",
      "0.02400\t\t0.0878378378\t52\t\t0.0122314050\n",
      "0.02200\t\t0.0875202593\t54\t\t0.0121876543\n",
      "0.02400\t\t0.0842433697\t54\t\t0.0121172023\n",
      "0.02200\t\t0.0860534125\t58\t\t0.0122046175\n",
      "0.03200\t\t0.0842857143\t59\t\t0.0121527778\n",
      "0.02600\t\t0.0886766712\t65\t\t0.0122115785\n",
      "0.02400\t\t0.0873533246\t67\t\t0.0122720000\n",
      "0.03000\t\t0.0869017632\t69\t\t0.0122106882\n",
      "0.02800\t\t0.0966183575\t80\t\t0.0122485207\n",
      "0.03400\t\t0.0971098266\t84\t\t0.0123175507\n",
      "0.02800\t\t0.0956618465\t86\t\t0.0123319616\n",
      "0.03400\t\t0.0960086300\t89\t\t0.0122578512\n",
      "0.03200\t\t0.0971488912\t92\t\t0.0120790816\n",
      "0.02200\t\t0.1051020408\t103\t\t0.0120652508\n",
      "0.02000\t\t0.1081349206\t109\t\t0.0119857313\n",
      "0.03000\t\t0.1053140097\t109\t\t0.0118931342\n",
      "0.02400\t\t0.1065801668\t115\t\t0.0119888889\n",
      "0.02200\t\t0.1063449508\t119\t\t0.0120290245\n",
      "0.01200\t\t0.1054925894\t121\t\t0.0119354839\n",
      "0.01000\t\t0.1025210084\t122\t\t0.0119929453\n",
      "0.02800\t\t0.1008950366\t124\t\t0.0120019531\n",
      "0.02200\t\t0.1010260458\t128\t\t0.0119952663\n",
      "0.01600\t\t0.0998463902\t130\t\t0.0119559229\n",
      "0.01000\t\t0.1023738872\t138\t\t0.0120115839\n",
      "0.02000\t\t0.1017793594\t143\t\t0.0121539792\n",
      "0.01800\t\t0.1011157601\t145\t\t0.0120478891\n",
      "0.01600\t\t0.1011386470\t151\t\t0.0121877551\n",
      "0.01400\t\t0.1047120419\t160\t\t0.0121245785\n",
      "0.01600\t\t0.1057014734\t165\t\t0.0120447531\n",
      "0.01400\t\t0.1071207430\t173\t\t0.0121223494\n",
      "0.01200\t\t0.1079136691\t180\t\t0.0121840760\n",
      "0.01800\t\t0.1093659104\t188\t\t0.0122240000\n",
      "0.01200\t\t0.1087699317\t191\t\t0.0121606648\n",
      "0.01400\t\t0.1096345515\t198\t\t0.0121841795\n",
      "0.01200\t\t0.1122559653\t207\t\t0.0121236029\n",
      "0.02200\t\t0.1108165429\t209\t\t0.0120878064\n",
      "0.02000\t\t0.1108234076\t214\t\t0.0120687500\n",
      "0.02200\t\t0.1106060606\t219\t\t0.0120713306\n",
      "0.02000\t\t0.1123706259\t228\t\t0.0120701963\n",
      "0.02600\t\t0.1115403187\t231\t\t0.0120249673\n",
      "0.02400\t\t0.1113216485\t235\t\t0.0119671202\n",
      "0.02600\t\t0.1096082090\t235\t\t0.0118698962\n",
      "0.02800\t\t0.1082686158\t237\t\t0.0118388318\n",
      "0.03000\t\t0.1090746536\t244\t\t0.0118219051\n",
      "0.03600\t\t0.1119370354\t256\t\t0.0118130165\n",
      "0.03400\t\t0.1136851137\t265\t\t0.0117712410\n",
      "0.02800\t\t0.1132631579\t269\t\t0.0117283951\n",
      "0.01800\t\t0.1118421053\t272\t\t0.0117473735\n",
      "0.02000\t\t0.1128061020\t281\t\t0.0117722117\n",
      "0.01800\t\t0.1129032258\t287\t\t0.0117562724\n",
      "0.02000\t\t0.1117964534\t290\t\t0.0117428701\n",
      "0.01000\t\t0.1121212121\t296\t\t0.0117008310\n",
      "0.01200\t\t0.1129211403\t305\t\t0.0117230903\n",
      "0.00200\t\t0.1167329237\t323\t\t0.0117632054\n",
      "0.00400\t\t0.1151536560\t326\t\t0.0117909204\n",
      "0.00600\t\t0.1165283541\t337\t\t0.0118028773\n",
      "0.00000\t\t0.1160258591\t341\t\t0.0117560000\n",
      "\n",
      "Assignments:\n",
      "[ 0  1  2  0  1  0  1  3  0  0  2  0  0  1  0  2  3  2  2  0  0  3  2  3  0  1  3  1  2  0  0  2  0  1  2  3  0  3  2  1  2  0  2  1  0  3  1  3  3  2  0  1  2  0  0  2  3  0  1  0  2  1  3  1  1  1  1  2  3  2  1  0  0  1  0  3  1  1  0  1  2  3  1  0  1  2  1  2  3  0  1  3  3  0  1  2  3  0  0  1  1  3  3  1  1  3  1  0  2  3  2  0  2  2  3  1  2  0  0  2  1  0  0  3  2  1  3  2  3  1  0  2  1  0  3  3  1  2  3  1  1  2  1  0  3  2  1  2  0  0  3  1  1  2  1  2  1  3  3  0  1  3  0  3  0  2  3  2  3  0  1  1  0  0  2  1  0  3  3  1  2  0  0  0  1  0  3  1  1  2  3  2  2  0  0  1  3  3  1  0  2  1  0  0  2  3  2  1  3  2  1  0  3  0  3  0  0  1  2  1  1  3  1  0  2  2  2  3  3  2  0  3  1  1  3  0  2  1  2  3  2  2  3  0  3  2  2  1  3  1  0  2  0  3  3  0  1  1  3  3  3  3  0  2  3  1  3  2  3  3  1  0  2  1  3  1  0  1  2  0  3  3  0  3  1  3  2  0  0  1  2  1  2  0  0  3  3  1  3  0  2  3  1  2  1  1  1  2  0  1  2  2  0  2  2  2  3  0  2  1  0  3  2  0  2  3  2  1  2  2  2  3  2  0  0  1  3  0  2  3  2  0  3  3  1  2  1  1  3  3  1  2  3  3  3  1  1  2  3  3  1  3  2  3  1  1  0  1  3  0  3  0  1  2  2  2  0  2  3  3  0  2  2  3  1  0  2  3  3  1  0  2  3  0  2  3  2  0  3  3  1  1  0  0  0  3  0  3  2  3  0  3  1  3  3  0  0  2  2  3  1  0  3  3  1  1  1  0  1  3  2  2  1  3  0  1  0  1  3  1  3  0  2  3  0  1  1  0  0  2  3  3  2  2  2  3  2  2  1  1  3  2  1  0  2  2  0  3  2  0  3  1  0  3  1  3  3  3  2  2  0  1  3  1  2  0  0  1  0  1  2  1  2  3  0  2  1  2  3  2  1  2  3  2  0  0  3  0  3  3  1  2  1  0  3  2  1  3  0  1  3  2  3  3  2  3  2  0  0  0  1  2  2  1  0  1  0  3  1  2  3  2  0  3  2  3  2  1  3  0  0  3  1  0  2  2  0  2  2  3  1  0  1  0  2  1  0  2  2  2  2  3  3  0  0  1  2  2  1  1  1  0  0  0  3  3  3  3  2  3  2  2  1  2  2  0  3  2  1  2  3  1  1  0  1  2  3  0  2  0  1  1  0  0  0  0  1  1  1  0  0  0  2  3  2  3  0  2  2  1  1  3  3  3  3  3  2  1  3  3  0  1  3  2  0  1  0  0  2  2  2  2  0  0  1  3  0  1  2  0  0  2  1  0  0  2  3  0  1  1  2  2  1  3  3  1  3  3  1  3  1  1  2  3  0  0  1  2  2  3  3  0  2  3  2  0  0  1  0  1  0  2  0  1  3  0  0  0  3  0  3  1  2  0  3  0  0  1  0  3  2  2  3  2  3  1  0  1  2  0  0  0  3  1  2  2  2  2  2  3  1  2  2  3  0  1  3  0  3  3  1  2  1  1  1  0  0  0  1  3  0  2  3  2  3  0  2  3  1  1  1  1  0  3  0  2  1  0  1  2  1  2  0  3  0  3  0  0  0  2  3  3  0  3  3  1  1  1  0  3  1  1  3  0  2  2  0  2  0  2  2  2  3  1  1  2  2  0  1  0  3  0  0  3  0  1  0  3  1  2  2  1  1  3  2  3  2  0  1  0  1  1  0  2  3  1  0  0  3  2  1  1  0  1  2  2  3  0  0  2  1  0  0  1  1  3  0  2  1  3  3  3  0  2  1  1  1  0  0  0  1  3  3  3  0  0  2  3  3  2  3  3  2  1  2  3  1  2  1  0  2  2  2  1  2  2  3  2  2  3  1  0  2  2  3  1  0  1  2  0  3  1  1  0  3  2  3  3  2  0  1  1  0  3  3  2  0  0  1  2  1  2  1  3  1  3  1  3  1  2  0  2  2  3  1  3  0  2  1  0  3  1  2  1  1  1  1  2  2  3  0  2  2  3  1  0  1  3  3  3  2  3  0  0  2  1  3  3  0  1  1  2  0  2  3  0  2  1  1  1]\n",
      "\n",
      "Fixed: 1000\n",
      "\n",
      "Partitions - nodes (weight):\n",
      "P0: 250.0 (250)\n",
      "P1: 250.0 (250)\n",
      "P2: 250.0 (250)\n",
      "P3: 250.0 (250)\n"
     ]
    }
   ],
   "source": [
    "if restream_batches == 1:\n",
    "    print(\"One-shot assignment mode\")\n",
    "    print(\"------------------------\\n\")\n",
    "else:\n",
    "    print(\"Assigning in batches of {}\".format(restream_batches))\n",
    "    print(\"--------------------------------\\n\")\n",
    "\n",
    "def edge_expansion(G):\n",
    "    # Update edge weights for nodes that have an assigned probability of displacement\n",
    "    for edge in G.edges_iter(data=True):\n",
    "        left = edge[0]\n",
    "        right = edge[1]\n",
    "        \n",
    "        if 'weight_orig' in edge[2]:\n",
    "            edge_weight = edge[2]['weight_orig']\n",
    "        else:\n",
    "            edge[2]['weight_orig'] = edge[2]['weight']\n",
    "            edge_weight = edge[2]['weight']\n",
    "\n",
    "        # new edge weight\n",
    "        edge[2]['weight'] = (float(G.node[left]['weight']) * edge_weight) * (float(G.node[right]['weight']) * edge_weight)\n",
    "\n",
    "    return G\n",
    "    \n",
    "batch_arrived = []\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\\tALPHA\")\n",
    "for a in arrival_order:\n",
    "\n",
    "    # check if node is already arrived\n",
    "    if fixed[a] == 1:\n",
    "        continue\n",
    "\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "    if graph_modification_functions:\n",
    "\n",
    "        # Set high node weight for those that need a shelter, and reduce for those that don't\n",
    "        if simulated_arrival_list[a] == 1:\n",
    "            G.node[a]['weight'] = 100\n",
    "        else:\n",
    "            G.node[a]['weight'] = 0\n",
    "            ## XXX remove node from graph\n",
    "            continue\n",
    "\n",
    "        G = edge_expansion(G)\n",
    "\n",
    "    # one-shot assigment: assign each node as it arrives\n",
    "    if restream_batches == 1:\n",
    "        alpha = one_shot_alpha\n",
    "        partition_votes = fennel.get_votes(G, a, num_partitions, assignments)\n",
    "        assignments[a] = fennel.get_assignment(G, a, num_partitions, assignments, partition_votes, alpha, 0)\n",
    "        fixed[a] = 1\n",
    "        nodes_arrived.append(a)\n",
    "\n",
    "        # make a subgraph of all arrived nodes\n",
    "        Gsub = G.subgraph(nodes_arrived)\n",
    "\n",
    "        x = shared.score(Gsub, assignments, num_partitions)\n",
    "        print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3:.10f}\".format(x[0], x[1], x[2], alpha))\n",
    "        continue\n",
    "\n",
    "    batch_arrived.append(a)\n",
    "\n",
    "    if restream_batches == len(batch_arrived):\n",
    "\n",
    "        # make a subgraph of all arrived nodes\n",
    "        Gsub = G.subgraph(nodes_arrived + batch_arrived)\n",
    "\n",
    "        # recalculate alpha\n",
    "        if Gsub.is_directed():\n",
    "            # as it's a directed graph, edges_arrived is actually double, so divide by 2\n",
    "            edges_arrived = Gsub.number_of_edges() / 2\n",
    "        else:\n",
    "            edges_arrived = Gsub.number_of_edges()\n",
    "        nodes_fixed = len([o for o in fixed if o == 1])\n",
    "        alpha = (edges_arrived) * (num_partitions / (nodes_fixed + len(batch_arrived))**2)\n",
    "\n",
    "        assignments = fennel.generate_prediction_model(G,\n",
    "                                                       num_iterations,\n",
    "                                                       num_partitions,\n",
    "                                                       assignments,\n",
    "                                                       fixed,\n",
    "                                                       alpha)\n",
    "\n",
    "        # assign nodes to prediction model\n",
    "        for n in batch_arrived:\n",
    "            fixed[n] = 1\n",
    "            nodes_arrived.append(n)\n",
    "\n",
    "        x = shared.score(Gsub, assignments, num_partitions)\n",
    "        print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3:.10f}\".format(x[0], x[1], x[2], alpha))\n",
    "        batch_arrived = []\n",
    "\n",
    "# remove nodes not fixed\n",
    "for i in range(0, len(assignments)):\n",
    "    if fixed[i] == -1:\n",
    "        assignments[i] = -1\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_virtual_nodes:\n",
    "    print(\"Remove virtual nodes\")\n",
    "    \n",
    "    print(\"\\nCurrent graph:\")\n",
    "    print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "    print(\"Edges: {}\".format(G.number_of_edges()))\n",
    "\n",
    "    G.remove_nodes_from(virtual_nodes)\n",
    "    assignments = np.delete(assignments, virtual_nodes)\n",
    "    fixed = np.delete(fixed, virtual_nodes)\n",
    "\n",
    "    print(\"\\nVirtual nodes removed:\")\n",
    "    print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "    print(\"Edges: {}\".format(G.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add partition attribute to nodes\n",
    "for i in range(0, len(assignments)):\n",
    "    G.add_nodes_from([i], partition=str(assignments[i]))\n",
    "\n",
    "# Freeze Graph from further modification\n",
    "G = nx.freeze(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete graph with 1000 nodes\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-all-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-all-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-all-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-all-edges-oslom.txt\n",
      "\n",
      "Config\n",
      "-------\n",
      "\n",
      "file: 215743\n",
      "num_partitions: 4\n",
      "num_iterations: 10\n",
      "prediction_model_cut_off: 0.1\n",
      "one_shot_alpha: 0.5\n",
      "restream_batches: 10\n",
      "use_virtual_nodes: False\n",
      "virtual_edge_weight: 1.0\n",
      "\n",
      "Metrics\n",
      "-------\n",
      "\n",
      "edges_cut: 341\n",
      "waste: 0.0\n",
      "cut_ratio: 0.11602585913576047\n",
      "communication_volume: 435\n",
      "network_permanence: 0.368160\n",
      "Q: -0.0012827457612951344\n",
      "NQ: -71.34113442306348\n",
      "Qds: -0.9999999999999944\n",
      "intraEdges: 0.0\n",
      "interEdges: 5.925403225806452\n",
      "intraDensity: 0.0\n",
      "modularity degree: -5878.0\n",
      "conductance: 1.0\n",
      "expansion: 5.925403225806452\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -1.3035186342505352E-9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%H%M%S')\n",
    "data_filename,_ = os.path.splitext(os.path.basename(DATA_FILENAME))\n",
    "data_filename += \"-\" + timestamp\n",
    "\n",
    "graph_metrics = {\n",
    "    \"file\": timestamp,\n",
    "    \"num_partitions\": num_partitions,\n",
    "    \"num_iterations\": num_iterations,\n",
    "    \"prediction_model_cut_off\": prediction_model_cut_off,\n",
    "    \"one_shot_alpha\": one_shot_alpha,\n",
    "    \"restream_batches\": restream_batches,\n",
    "    \"use_virtual_nodes\": use_virtual_nodes,\n",
    "    \"virtual_edge_weight\": virtual_edge_weight,\n",
    "}\n",
    "graph_fieldnames = [\n",
    "    \"file\",\n",
    "    \"num_partitions\",\n",
    "    \"num_iterations\",\n",
    "    \"prediction_model_cut_off\",\n",
    "    \"one_shot_alpha\",\n",
    "    \"restream_batches\",\n",
    "    \"use_virtual_nodes\",\n",
    "    \"virtual_edge_weight\",\n",
    "    \"edges_cut\",\n",
    "    \"waste\",\n",
    "    \"cut_ratio\",\n",
    "    \"communication_volume\",\n",
    "    \"network_permanence\",\n",
    "    \"Q\",\n",
    "    \"NQ\",\n",
    "    \"Qds\",\n",
    "    \"intraEdges\",\n",
    "    \"interEdges\",\n",
    "    \"intraDensity\",\n",
    "    \"modularity degree\",\n",
    "    \"conductance\",\n",
    "    \"expansion\",\n",
    "    \"contraction\",\n",
    "    \"fitness\",\n",
    "    \"QovL\",\n",
    "]\n",
    "\n",
    "print(\"Complete graph with {} nodes\".format(G.number_of_nodes()))\n",
    "(file_maxperm, file_oslom) = shared.write_graph_files(OUTPUT_DIRECTORY, \"{}-all\".format(data_filename), G)\n",
    "\n",
    "# original scoring algorithm\n",
    "scoring = shared.score(G, assignments, num_partitions)\n",
    "graph_metrics.update({\n",
    "    \"waste\": scoring[0],\n",
    "    \"cut_ratio\": scoring[1],\n",
    "})\n",
    "\n",
    "# edges cut and communication volume\n",
    "edges_cut, steps = shared.base_metrics(G)\n",
    "graph_metrics.update({\n",
    "    \"edges_cut\": edges_cut,\n",
    "    \"communication_volume\": steps,\n",
    "})\n",
    "\n",
    "# MaxPerm\n",
    "max_perm = shared.run_max_perm(file_maxperm)\n",
    "graph_metrics.update({\"network_permanence\": max_perm})\n",
    "\n",
    "# Community Quality metrics\n",
    "community_metrics = shared.run_community_metrics(OUTPUT_DIRECTORY,\n",
    "                                                 \"{}-all\".format(data_filename),\n",
    "                                                 file_oslom)\n",
    "graph_metrics.update(community_metrics)\n",
    "\n",
    "print(\"\\nConfig\")\n",
    "print(\"-------\\n\")\n",
    "for f in graph_fieldnames[:8]:\n",
    "    print(\"{}: {}\".format(f, graph_metrics[f]))\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\"-------\\n\")\n",
    "for f in graph_fieldnames[8:]:\n",
    "    print(\"{}: {}\".format(f, graph_metrics[f]))\n",
    "\n",
    "# write metrics to CSV\n",
    "metrics_filename = os.path.join(OUTPUT_DIRECTORY, \"metrics.csv\")\n",
    "shared.write_metrics_csv(metrics_filename, graph_fieldnames, graph_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Partition 0 with 250 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p0-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p0-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p0-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p0-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 215743\n",
      "partition: 0\n",
      "network_permanence: 1.000000\n",
      "Q: -0.005343396263151615\n",
      "NQ: -18.614258427451404\n",
      "Qds: -0.999999999999999\n",
      "intraEdges: 0.0\n",
      "interEdges: 5.211382113821138\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1282.0\n",
      "conductance: 1.0\n",
      "expansion: 5.211382113821138\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -8.829724805260795E-8\n",
      "\n",
      "Partition 1 with 250 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p1-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p1-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p1-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p1-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 215743\n",
      "partition: 1\n",
      "network_permanence: 1.000000\n",
      "Q: -0.005013926018724625\n",
      "NQ: -19.135158149658583\n",
      "Qds: -1.000000000000003\n",
      "intraEdges: 0.0\n",
      "interEdges: 4.803212851405623\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1196.0\n",
      "conductance: 1.0\n",
      "expansion: 4.803212851405623\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -8.086847016539441E-8\n",
      "\n",
      "Partition 2 with 250 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p2-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p2-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p2-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p2-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 215743\n",
      "partition: 2\n",
      "network_permanence: 1.000000\n",
      "Q: -0.0051300312809218415\n",
      "NQ: -15.967649428630224\n",
      "Qds: -0.9999999999999998\n",
      "intraEdges: 0.0\n",
      "interEdges: 5.686746987951807\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1416.0\n",
      "conductance: 1.0\n",
      "expansion: 5.686746987951807\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -8.274110548090882E-8\n",
      "\n",
      "Partition 3 with 250 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p3-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p3-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p3-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-215743-p3-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 215743\n",
      "partition: 3\n",
      "network_permanence: 1.000000\n",
      "Q: -0.005228869209841403\n",
      "NQ: -18.110914191717324\n",
      "Qds: -1.0000000000000002\n",
      "intraEdges: 0.0\n",
      "interEdges: 5.2926829268292686\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1302.0\n",
      "conductance: 1.0\n",
      "expansion: 5.2926829268292686\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -8.640473940513948E-8\n"
     ]
    }
   ],
   "source": [
    "partition_metrics = {}\n",
    "partition_fieldnames = [\n",
    "    \"file\",\n",
    "    \"partition\",\n",
    "    \"network_permanence\",\n",
    "    \"Q\",\n",
    "    \"NQ\",\n",
    "    \"Qds\",\n",
    "    \"intraEdges\",\n",
    "    \"interEdges\",\n",
    "    \"intraDensity\",\n",
    "    \"modularity degree\",\n",
    "    \"conductance\",\n",
    "    \"expansion\",\n",
    "    \"contraction\",\n",
    "    \"fitness\",\n",
    "    \"QovL\",\n",
    "]\n",
    "\n",
    "for p in range(0, num_partitions):\n",
    "    partition_metrics = {\n",
    "        \"file\": timestamp,\n",
    "        \"partition\": p\n",
    "    }\n",
    "\n",
    "    nodes = [i for i,x in enumerate(assignments) if x == p]\n",
    "    Gsub = G.subgraph(nodes)\n",
    "    print(\"\\nPartition {} with {} nodes\".format(p, Gsub.number_of_nodes()))\n",
    "    print(\"-----------------------------\\n\")\n",
    "\n",
    "    (file_maxperm, file_oslom) = shared.write_graph_files(OUTPUT_DIRECTORY, \"{}-p{}\".format(data_filename, p), Gsub)\n",
    "    \n",
    "    # MaxPerm\n",
    "    max_perm = shared.run_max_perm(file_maxperm)\n",
    "    partition_metrics.update({\"network_permanence\": max_perm})\n",
    "\n",
    "    # Community Quality metrics\n",
    "    community_metrics = shared.run_community_metrics(OUTPUT_DIRECTORY,\n",
    "                                                     \"{}-p{}\".format(data_filename, p),\n",
    "                                                     file_oslom)\n",
    "    partition_metrics.update(community_metrics)\n",
    "\n",
    "    print(\"\\nMetrics\")\n",
    "    for f in partition_fieldnames:\n",
    "        print(\"{}: {}\".format(f, partition_metrics[f]))\n",
    "\n",
    "    # write metrics to CSV\n",
    "    metrics_filename = os.path.join(OUTPUT_DIRECTORY, \"metrics-partitions.csv\")\n",
    "    shared.write_metrics_csv(metrics_filename, partition_fieldnames, partition_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
