{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded...\n",
      "Nodes: 1000\n",
      "Edges: 2939\n",
      "Graph is undirected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shared\n",
    "import networkx as nx\n",
    "\n",
    "pwd = %pwd\n",
    "\n",
    "DATA_FILENAME = os.path.join(pwd, \"data\", \"oneshot_fennel_weights.txt\")\n",
    "OUTPUT_DIRECTORY = os.path.join(pwd, \"output\")\n",
    "\n",
    "# Read input file for prediction model, if not provided a prediction\n",
    "# model is made using FENNEL\n",
    "PREDICTION_MODEL = \"\"\n",
    "\n",
    "# File containing simulated arrivals. This is used in simulating nodes\n",
    "# arriving at the shelter. Nodes represented by line number; value of\n",
    "# 1 represents a node as arrived; value of 0 represents the node as not\n",
    "# arrived or needing a shelter.\n",
    "#SIMULATED_ARRIVAL_FILE = os.path.join(pwd, \"data\", \"simulated_arrival.txt\")\n",
    "SIMULATED_ARRIVAL_FILE = \"\"\n",
    "\n",
    "# File containing the geographic location of each node.\n",
    "POPULATION_LOCATION_FILE = os.path.join(pwd, \"data\", \"population_location.csv\")\n",
    "\n",
    "# Number of shelters\n",
    "num_partitions = 4\n",
    "\n",
    "# The number of iterations when making prediction model\n",
    "num_iterations = 10\n",
    "\n",
    "# Percentage of prediction model to use before discarding\n",
    "# When set to 0, prediction model is discarded, useful for one-shot\n",
    "prediction_model_cut_off = 0.10\n",
    "\n",
    "# Alpha value used in one-shot (when restream_batches set to 1)\n",
    "one_shot_alpha = 0.5\n",
    "\n",
    "# Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "# When set to 1, one-shot is used with alpha value from above\n",
    "restream_batches = 10\n",
    "\n",
    "# Create virtual nodes based on prediction model\n",
    "use_virtual_nodes = False\n",
    "\n",
    "# Virtual nodes: edge weight\n",
    "virtual_edge_weight = 1.0\n",
    "\n",
    "\n",
    "####\n",
    "# GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "# Also enables the edge calculation function.\n",
    "graph_modification_functions = True\n",
    "\n",
    "# If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "# otherwise the node is removed from the graph.\n",
    "alter_arrived_node_weight_to_100 = False\n",
    "\n",
    "# Uses generalized additive models from R to generate prediction of nodes not\n",
    "# arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "# given by a GAM.\n",
    "# Needs POPULATION_LOCATION_FILE to be set.\n",
    "alter_node_weight_to_gam_prediction = False\n",
    "\n",
    "# Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "# de-emphasise the prediction model for the unknown nodes.\n",
    "prediction_model_emphasis = 1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read METIS file\n",
    "G = shared.read_metis(DATA_FILENAME)\n",
    "\n",
    "# Alpha value used in prediction model\n",
    "prediction_model_alpha = G.number_of_edges() * (num_partitions / G.number_of_nodes()**2)\n",
    "\n",
    "# Order of nodes arriving\n",
    "arrival_order = list(range(0, G.number_of_nodes()))\n",
    "\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(arrival_order)\n",
    "\n",
    "if SIMULATED_ARRIVAL_FILE == \"\":\n",
    "    # mark all nodes as needing a shelter\n",
    "    simulated_arrival_list = [1]*G.number_of_nodes()\n",
    "else:\n",
    "    with open(SIMULATED_ARRIVAL_FILE, \"r\") as f:\n",
    "        simulated_arrival_list = [int(line.rstrip('\\n')) for line in f]\n",
    "\n",
    "print(\"Graph loaded...\")\n",
    "print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "print(\"Edges: {}\".format(G.number_of_edges()))\n",
    "if nx.is_directed(G):\n",
    "    print(\"Graph is directed\")\n",
    "else:\n",
    "    print(\"Graph is undirected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION MODEL\n",
      "----------------\n",
      "\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\n",
      "0.00000\t\t0.1224906431\t360\n",
      "\n",
      "Assignments:\n",
      "[ 0  1  2  0  1  0  1  3  0  0  2  0  0  1  0  2  3  2  2  0  0  3  2  3  0  1  3  1  2  0  0  2  0  1  2  3  0  3  2  1  2  0  2  1  0  3  1  3  3  2  0  1  2  0  0  2  3  0  1  0  2  1  3  1  1  1  1  2  3  2  1  0  0  1  0  3  1  1  0  1  2  3  1  0  1  2  1  2  3  0  1  3  3  0  1  2  3  0  0  1  1  2  3  1  1  0  1  0  2  0  2  1  2  2  3  1  3  1  0  2  1  0  0  3  1  1  3  2  2  3  0  0  1  0  0  3  1  2  3  1  1  2  3  2  3  2  1  2  0  0  3  1  1  2  1  2  1  3  3  0  1  3  0  3  0  2  3  2  3  1  0  1  0  1  2  1  0  2  1  1  2  0  0  0  1  0  2  1  1  2  3  2  2  0  0  3  1  2  3  0  2  1  0  3  2  2  2  1  2  2  1  0  3  0  3  0  0  1  2  3  0  3  1  0  2  2  2  2  1  2  3  3  1  1  3  3  2  1  0  3  2  2  2  3  3  2  2  1  1  3  0  2  0  3  3  0  1  2  1  1  3  1  0  2  3  1  3  2  3  3  1  0  2  3  0  1  0  1  2  3  2  3  1  2  0  3  2  0  0  1  1  3  2  0  0  3  3  1  3  0  1  2  3  0  3  1  1  0  3  1  2  2  0  2  2  2  3  0  2  3  0  3  0  0  2  3  2  1  1  2  2  1  2  0  0  1  3  3  2  3  2  0  2  3  3  2  0  1  3  3  1  2  1  3  3  1  1  2  3  0  1  3  2  3  1  1  0  1  3  0  1  3  0  2  2  2  3  2  2  3  0  2  2  3  1  3  2  3  3  1  0  2  3  0  2  2  2  0  3  3  1  1  0  0  0  3  0  3  2  3  0  3  1  2  3  0  0  2  1  3  1  0  3  3  1  0  0  3  1  3  2  1  1  2  3  2  3  1  3  1  3  0  2  3  0  1  1  0  3  2  3  3  2  2  2  1  2  2  1  3  0  2  1  0  2  2  0  3  1  0  3  1  1  2  1  1  3  3  2  2  0  1  1  3  0  0  0  1  0  1  2  1  0  3  0  2  1  2  3  2  0  2  3  2  3  0  0  0  1  1  3  2  0  3  3  2  0  1  0  1  3  1  1  3  2  3  2  1  3  0  1  2  2  1  0  3  0  3  1  0  3  2  3  3  2  2  0  1  3  2  0  3  3  2  1  1  0  0  0  2  1  1  3  0  3  1  3  2  1  2  2  2  0  1  0  1  2  0  1  0  1  2  0  2  3  3  2  1  2  0  2  2  1  2  2  0  0  0  1  0  3  3  1  3  1  3  3  1  2  0  0  1  0  0  0  2  1  1  1  1  0  0  2  3  2  3  0  2  2  3  1  3  3  3  3  3  2  1  0  3  0  3  3  0  0  1  0  2  2  1  3  2  1  0  1  3  1  2  2  3  1  2  3  0  0  2  2  0  1  1  2  1  3  0  3  1  3  3  3  3  3  1  2  3  0  0  3  2  2  3  3  3  2  3  2  0  0  1  0  1  0  2  0  3  3  0  1  0  3  0  3  2  3  0  3  0  0  1  0  3  2  2  3  3  0  0  0  3  2  0  0  0  3  1  0  2  2  2  2  3  1  2  2  3  1  0  2  0  2  3  1  2  1  2  1  0  0  0  1  3  0  0  3  2  3  0  2  1  3  3  2  1  1  3  3  2  1  1  1  1  0  1  0  3  1  1  3  0  2  1  3  2  0  3  3  1  1  1  0  3  1  3  3  3  2  2  2  2  0  2  2  2  3  1  1  2  3  0  1  0  3  0  0  0  2  1  0  3  1  2  2  3  1  3  2  3  2  3  1  0  1  1  0  2  3  0  0  0  3  2  3  1  0  1  2  2  3  0  3  2  0  0  0  1  1  1  0  1  1  3  1  3  0  1  2  1  1  2  0  0  3  3  2  3  3  0  2  3  2  0  1  0  2  0  0  3  1  2  1  0  2  2  0  0  0  1  3  2  2  1  1  1  0  1  0  3  0  3  2  0  3  1  1  1  3  2  3  3  2  0  1  1  2  1  1  1  0  0  1  2  1  2  3  3  1  3  0  3  1  3  0  2  2  2  0  2  0  2  0  0  3  3  2  2  1  1  1  2  1  2  0  2  2  3  1  1  1  3  3  2  2  2  0  3  2  1  3  2  0  1  0  0  0  0  3  0  2  3  1  1]\n",
      "\n",
      "Fixed: 0\n",
      "\n",
      "Partitions - nodes (weight):\n",
      "P0: 250.0 (250)\n",
      "P1: 250.0 (250)\n",
      "P2: 250.0 (250)\n",
      "P3: 250.0 (250)\n"
     ]
    }
   ],
   "source": [
    "import pyximport; pyximport.install()\n",
    "import fennel\n",
    "import numpy as np\n",
    "\n",
    "UNMAPPED = -1\n",
    "\n",
    "# reset\n",
    "assignments = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "fixed = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "\n",
    "print(\"PREDICTION MODEL\")\n",
    "print(\"----------------\\n\")\n",
    "\n",
    "if PREDICTION_MODEL:\n",
    "    with open(PREDICTION_MODEL, \"r\") as inf:\n",
    "        assignments = np.fromiter(inf.readlines(), dtype=np.int32)\n",
    "\n",
    "else:\n",
    "    assignments = fennel.generate_prediction_model(G, num_iterations, num_partitions, assignments, fixed, prediction_model_alpha)\n",
    "\n",
    "x = shared.score(G, assignments)\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\")\n",
    "print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\".format(x[0], x[1], x[2]))\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_virtual_nodes:\n",
    "    print(\"Creating virtual nodes and assigning edges based on prediction model\")\n",
    "\n",
    "    # create virtual nodes\n",
    "    virtual_nodes = list(range(G.number_of_nodes(), G.number_of_nodes() + num_partitions))\n",
    "    print(\"\\nVirtual nodes:\")\n",
    "\n",
    "    # create virtual edges\n",
    "    virtual_edges = []\n",
    "    for n in range(0, G.number_of_nodes()):\n",
    "        virtual_edges += [(n, virtual_nodes[assignments[n]])]\n",
    "\n",
    "    # extend assignments\n",
    "    assignments = np.append(assignments, np.array(list(range(0, num_partitions)), dtype=np.int32))\n",
    "    fixed = np.append(fixed, np.array([1] * num_partitions, dtype=np.int32))\n",
    "\n",
    "    G.add_nodes_from(virtual_nodes, weight=1)\n",
    "    G.add_edges_from(virtual_edges, weight=virtual_edge_weight)\n",
    "\n",
    "    print(\"\\nAssignments:\")\n",
    "    shared.fixed_width_print(assignments)\n",
    "    print(\"Last {} nodes are virtual nodes.\".format(num_partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign first 100 arrivals using prediction model, then discard\n",
      "\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\n",
      "0.02400\t\t0.1861177271\t547\n",
      "\n",
      "Assignments:\n",
      "[ 0  1  2  0  1  0  1  3  0  0  2  0  0  1  0  2  3  2  2  0  0  3  2  3  0  1  3  1  2  0  0  2  0  1  2  3  0  3  2  1  2  0  2  1  0  3  1  3  3  2  0  1  2  0  0  2  3  0  1  0  2  1  3  1  1  1  1  2  3  2  1  0  0  1  0  3  1  1  0  1  2  3  1  0  1  2  1  2  3  0  1  3  3  0  1  2  3  0  0  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "\n",
      "Fixed: 100\n",
      "\n",
      "Partitions - nodes:\n",
      "P0: 31\n",
      "P1: 28\n",
      "P2: 22\n",
      "P3: 19\n"
     ]
    }
   ],
   "source": [
    "cut_off_value = int(prediction_model_cut_off * G.number_of_nodes())\n",
    "if prediction_model_cut_off == 0:\n",
    "    print(\"Discarding prediction model\\n\")\n",
    "else:\n",
    "    print(\"Assign first {} arrivals using prediction model, then discard\\n\".format(cut_off_value))\n",
    "\n",
    "# fix arrivals\n",
    "nodes_arrived = []\n",
    "for a in arrival_order:\n",
    "    # check if node needs a shelter\n",
    "    if simulated_arrival_list[a] == 0:\n",
    "        continue\n",
    "\n",
    "    # set 100% node weight for those that need a shelter\n",
    "    if alter_arrived_node_weight_to_100:\n",
    "        G.node[a]['weight'] = 100\n",
    "\n",
    "    nodes_fixed = len([o for o in fixed if o == 1])\n",
    "    if nodes_fixed >= cut_off_value:\n",
    "        break\n",
    "    fixed[a] = 1\n",
    "    nodes_arrived.append(a)\n",
    "\n",
    "# remove nodes not fixed, ie. discard prediction model\n",
    "for i in range(0, len(assignments)):\n",
    "    if fixed[i] == -1:\n",
    "        assignments[i] = -1\n",
    "\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\")\n",
    "x = shared.score(G, assignments, num_partitions)\n",
    "print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\".format(x[0], x[1], x[2]))\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning in batches of 10\n",
      "--------------------------------\n",
      "\n",
      "WASTE\t\tCUT RATIO\tMISMATCH\tALPHA\n",
      "0.01800\t\t0.0000000000\t0\t\t0.0102479339\n",
      "0.01200\t\t0.0263157895\t1\t\t0.0105555556\n",
      "0.01000\t\t0.0232558140\t1\t\t0.0101775148\n",
      "0.00800\t\t0.0196078431\t1\t\t0.0104081633\n",
      "0.00200\t\t0.0151515152\t1\t\t0.0117333333\n",
      "0.00400\t\t0.0129870130\t1\t\t0.0120312500\n",
      "0.00200\t\t0.0232558140\t2\t\t0.0119031142\n",
      "0.00400\t\t0.0300000000\t3\t\t0.0123456790\n",
      "0.00600\t\t0.0438596491\t5\t\t0.0126315789\n",
      "0.00000\t\t0.0655737705\t8\t\t0.0122000000\n",
      "0.00200\t\t0.0724637681\t10\t\t0.0125170068\n",
      "0.00000\t\t0.0915032680\t14\t\t0.0126446281\n",
      "0.00600\t\t0.0931677019\t15\t\t0.0121739130\n",
      "0.00000\t\t0.0935672515\t16\t\t0.0118750000\n",
      "0.00200\t\t0.0944444444\t17\t\t0.0115200000\n",
      "0.00000\t\t0.0984455959\t19\t\t0.0114201183\n",
      "0.00200\t\t0.0931372549\t19\t\t0.0111934156\n",
      "0.00000\t\t0.0986547085\t22\t\t0.0113775510\n",
      "0.00600\t\t0.1152263374\t28\t\t0.0115576694\n",
      "0.00400\t\t0.1167315175\t30\t\t0.0114222222\n",
      "0.01400\t\t0.1163636364\t32\t\t0.0114464100\n",
      "0.00400\t\t0.1122112211\t34\t\t0.0118359375\n",
      "0.00600\t\t0.1086956522\t35\t\t0.0118273646\n",
      "0.00800\t\t0.1068249258\t36\t\t0.0116608997\n",
      "0.00600\t\t0.1101928375\t40\t\t0.0118530612\n",
      "0.00000\t\t0.1159793814\t45\t\t0.0119753086\n",
      "0.00200\t\t0.1160493827\t47\t\t0.0118334551\n",
      "0.00800\t\t0.1162790698\t50\t\t0.0119113573\n",
      "0.00600\t\t0.1167400881\t53\t\t0.0119395135\n",
      "0.00800\t\t0.1129707113\t54\t\t0.0119500000\n",
      "0.00600\t\t0.1139489194\t58\t\t0.0121118382\n",
      "0.00800\t\t0.1197053407\t65\t\t0.0123129252\n",
      "0.01000\t\t0.1278458844\t73\t\t0.0123526230\n",
      "0.00800\t\t0.1300675676\t77\t\t0.0122314050\n",
      "0.00600\t\t0.1312803890\t81\t\t0.0121876543\n",
      "0.00800\t\t0.1310452418\t84\t\t0.0121172023\n",
      "0.00600\t\t0.1335311573\t90\t\t0.0122046175\n",
      "0.00400\t\t0.1342857143\t94\t\t0.0121527778\n",
      "0.00600\t\t0.1377899045\t101\t\t0.0122115785\n",
      "0.00000\t\t0.1395045632\t107\t\t0.0122720000\n",
      "0.00200\t\t0.1423173804\t113\t\t0.0122106882\n",
      "0.00400\t\t0.1497584541\t124\t\t0.0122485207\n",
      "0.00200\t\t0.1491329480\t129\t\t0.0123175507\n",
      "0.00400\t\t0.1479421580\t133\t\t0.0123319616\n",
      "0.00200\t\t0.1499460626\t139\t\t0.0122578512\n",
      "0.00000\t\t0.1488912355\t141\t\t0.0120790816\n",
      "0.00200\t\t0.1540816327\t151\t\t0.0120652508\n",
      "0.00400\t\t0.1537698413\t155\t\t0.0119857313\n",
      "0.00200\t\t0.1516908213\t157\t\t0.0118931342\n",
      "0.00400\t\t0.1556997220\t168\t\t0.0119888889\n",
      "0.00200\t\t0.1590705987\t178\t\t0.0120290245\n",
      "0.00400\t\t0.1595466434\t183\t\t0.0119354839\n",
      "0.00200\t\t0.1579831933\t188\t\t0.0119929453\n",
      "0.00400\t\t0.1578519121\t194\t\t0.0120019531\n",
      "0.00600\t\t0.1586424625\t201\t\t0.0119952663\n",
      "0.00800\t\t0.1559139785\t203\t\t0.0119559229\n",
      "0.01000\t\t0.1580118694\t213\t\t0.0120115839\n",
      "0.00000\t\t0.1587188612\t223\t\t0.0121539792\n",
      "0.00600\t\t0.1582984658\t227\t\t0.0120478891\n",
      "0.00800\t\t0.1587407904\t237\t\t0.0121877551\n",
      "0.01000\t\t0.1642670157\t251\t\t0.0121245785\n",
      "0.01200\t\t0.1659192825\t259\t\t0.0120447531\n",
      "0.01400\t\t0.1684210526\t272\t\t0.0121223494\n",
      "0.01200\t\t0.1714628297\t286\t\t0.0121840760\n",
      "0.01800\t\t0.1716114020\t295\t\t0.0122240000\n",
      "0.01200\t\t0.1719817768\t302\t\t0.0121606648\n",
      "0.01400\t\t0.1760797342\t318\t\t0.0121841795\n",
      "0.00800\t\t0.1762472885\t325\t\t0.0121236029\n",
      "0.01000\t\t0.1797454931\t339\t\t0.0120878064\n",
      "0.00800\t\t0.1791817711\t346\t\t0.0120687500\n",
      "0.01000\t\t0.1792929293\t355\t\t0.0120713306\n",
      "0.00800\t\t0.1784130113\t362\t\t0.0120701963\n",
      "0.01400\t\t0.1786576533\t370\t\t0.0120249673\n",
      "0.00800\t\t0.1790620559\t378\t\t0.0119671202\n",
      "0.01000\t\t0.1781716418\t382\t\t0.0118698962\n",
      "0.01200\t\t0.1781635450\t390\t\t0.0118388318\n",
      "0.02600\t\t0.1797049620\t402\t\t0.0118219051\n",
      "0.03200\t\t0.1823349366\t417\t\t0.0118130165\n",
      "0.03000\t\t0.1836121836\t428\t\t0.0117712410\n",
      "0.03600\t\t0.1827368421\t434\t\t0.0117283951\n",
      "0.03800\t\t0.1846217105\t449\t\t0.0117473735\n",
      "0.03200\t\t0.1882778001\t469\t\t0.0117722117\n",
      "0.03000\t\t0.1884343037\t479\t\t0.0117562724\n",
      "0.03200\t\t0.1900539707\t493\t\t0.0117428701\n",
      "0.03400\t\t0.1901515152\t502\t\t0.0117008310\n",
      "0.02800\t\t0.1917808219\t518\t\t0.0117230903\n",
      "0.03400\t\t0.1929887965\t534\t\t0.0117632054\n",
      "0.02800\t\t0.1921582480\t544\t\t0.0117909204\n",
      "0.02600\t\t0.1939834025\t561\t\t0.0118028773\n",
      "0.03600\t\t0.1942837700\t571\t\t0.0117560000\n",
      "\n",
      "Assignments:\n",
      "[ 0  1  2  0  1  0  1  3  0  0  2  0  0  1  0  2  3  2  2  0  0  3  2  3  0  1  3  1  2  0  0  2  0  1  2  3  0  3  2  1  2  0  2  1  0  3  1  3  3  2  0  1  2  0  0  2  3  0  1  0  2  1  3  1  1  1  1  2  3  2  1  0  0  1  0  3  1  1  0  1  2  3  1  0  1  2  1  2  3  0  1  3  3  0  1  2  3  0  0  1  1  3  3  3  2  3  1  0  2  3  2  3  3  2  3  1  2  2  0  3  2  0  0  3  3  1  3  2  3  2  0  2  1  0  3  1  2  2  3  1  1  2  2  3  3  3  1  2  0  1  3  1  2  2  1  0  1  3  0  2  1  3  2  3  0  0  3  2  0  1  1  1  0  3  2  2  0  3  2  1  3  0  0  2  1  0  3  1  1  2  2  3  2  3  0  1  2  3  3  0  0  1  0  3  2  0  2  1  3  1  1  0  3  2  3  0  3  1  2  2  1  0  1  0  2  2  3  3  2  2  0  3  1  1  3  0  2  1  3  0  0  2  3  3  0  3  2  1  1  0  0  2  2  1  3  0  1  1  3  2  1  3  0  2  3  1  0  2  3  0  1  0  2  3  1  1  0  2  2  3  2  1  3  2  3  0  2  2  0  1  1  3  2  0  3  0  1  1  0  0  3  3  2  1  1  1  1  1  0  1  2  2  0  2  0  2  3  0  3  3  0  3  3  0  2  0  0  1  3  2  2  3  0  0  0  1  1  3  2  1  0  1  2  3  3  2  1  2  0  3  1  0  2  3  3  3  1  2  2  1  2  3  2  3  1  2  0  1  3  0  1  3  0  0  2  2  3  2  3  2  0  0  2  3  1  3  2  1  3  1  1  0  3  0  2  2  2  0  3  0  1  1  0  0  0  1  3  3  2  3  0  3  1  3  2  0  2  2  1  3  1  0  3  1  1  1  1  3  3  2  2  2  1  3  0  2  3  1  0  1  2  3  2  3  0  0  1  0  0  2  1  0  2  0  2  1  2  0  2  3  1  2  1  0  3  2  0  3  1  0  3  1  0  3  1  3  2  0  1  2  0  1  1  3  2  0  0  1  0  1  2  1  3  3  0  2  1  2  3  3  1  2  3  0  3  0  3  0  1  1  1  2  1  0  3  2  0  3  0  2  3  2  1  1  2  3  2  0  3  0  1  2  2  0  0  3  0  2  1  1  0  3  3  3  2  2  1  1  1  3  0  1  3  0  1  3  0  2  2  2  1  0  3  0  2  1  0  2  3  2  2  2  3  3  0  1  3  3  1  1  1  0  0  0  3  3  2  1  2  1  2  2  3  2  2  0  3  1  1  0  3  1  1  0  1  2  3  0  2  0  3  1  3  0  0  3  2  1  1  0  0  0  2  3  2  3  0  2  2  1  1  3  3  3  0  1  2  1  0  1  0  2  3  3  0  1  0  0  2  2  3  2  2  0  1  3  0  1  2  0  2  2  1  0  0  2  3  0  1  1  2  3  1  3  3  1  3  3  2  1  2  1  3  1  0  0  2  2  2  1  0  0  2  3  2  0  0  1  0  1  1  2  1  3  1  0  3  1  0  0  3  1  3  0  3  1  0  1  0  1  2  2  3  2  3  0  0  2  2  0  0  0  3  1  2  2  3  2  2  3  0  2  2  0  3  0  3  0  3  3  3  2  1  1  1  0  3  2  1  3  0  1  1  2  3  0  0  3  1  3  2  1  1  3  0  2  1  2  1  3  1  2  0  3  3  2  0  2  0  3  3  3  0  1  3  1  1  1  0  2  1  2  3  0  2  2  0  1  0  2  2  2  3  1  1  2  2  0  1  0  3  0  0  3  3  1  0  3  1  0  2  3  1  3  2  1  2  0  1  2  1  1  0  2  1  1  0  0  1  2  3  1  0  1  2  2  1  0  0  2  1  0  0  1  1  1  0  1  1  3  1  3  0  3  1  1  1  0  0  0  2  0  2  3  0  3  3  1  3  1  1  3  2  1  2  3  1  2  1  0  2  2  3  1  1  3  1  2  2  2  1  0  2  3  3  3  0  2  2  0  3  1  1  3  3  3  3  3  2  0  1  1  0  3  2  3  0  0  1  3  1  2  3  3  2  3  1  3  1  2  0  2  2  3  0  2  0  2  1  3  3  3  2  1  1  1  1  2  3  2  0  2  2  3  1  2  2  0  2  3  2  3  2  0  0  1  3  3  0  1  1  1  2  2  0  0  2  1  1  1]\n",
      "\n",
      "Fixed: 1000\n",
      "\n",
      "Partitions - nodes (weight):\n",
      "P0: 245.0 (245)\n",
      "P1: 259.0 (259)\n",
      "P2: 250.0 (250)\n",
      "P3: 246.0 (246)\n"
     ]
    }
   ],
   "source": [
    "if restream_batches == 1:\n",
    "    print(\"One-shot assignment mode\")\n",
    "    print(\"------------------------\\n\")\n",
    "else:\n",
    "    print(\"Assigning in batches of {}\".format(restream_batches))\n",
    "    print(\"--------------------------------\\n\")\n",
    "\n",
    "def edge_expansion(G):\n",
    "    # Update edge weights for nodes that have an assigned probability of displacement\n",
    "    for edge in G.edges_iter(data=True):\n",
    "        left = edge[0]\n",
    "        right = edge[1]\n",
    "        edge_weight = edge[2]['weight_orig']\n",
    "\n",
    "        # new edge weight\n",
    "        edge[2]['weight'] = (float(G.node[left]['weight']) * edge_weight) * (float(G.node[right]['weight']) * edge_weight)\n",
    "\n",
    "        if left in nodes_arrived or right in nodes_arrived:\n",
    "            # change the emphasis of the prediction model\n",
    "            edge[2]['weight'] = edge[2]['weight'] * prediction_model_emphasis\n",
    "\n",
    "    return G\n",
    "\n",
    "# preserve original node/edge weight\n",
    "if graph_modification_functions:\n",
    "    node_weights = {n[0]: n[1]['weight'] for n in G.nodes_iter(data=True)}\n",
    "    nx.set_node_attributes(G, 'weight_orig', node_weights)\n",
    "\n",
    "    edge_weights = {(e[0], e[1]): e[2]['weight'] for e in G.edges_iter(data=True)}\n",
    "    nx.set_edge_attributes(G, 'weight_orig', edge_weights)\n",
    "\n",
    "    \n",
    "batch_arrived = []\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tMISMATCH\\tALPHA\")\n",
    "for a in arrival_order:\n",
    "\n",
    "    # check if node is already arrived\n",
    "    if fixed[a] == 1:\n",
    "        continue\n",
    "\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "    if graph_modification_functions:\n",
    "\n",
    "        # remove nodes that don't need a shelter\n",
    "        if simulated_arrival_list[a] == 0:\n",
    "            G.remove_node(a)\n",
    "            continue\n",
    "        \n",
    "        # set 100% node weight for those that need a shelter\n",
    "        if alter_arrived_node_weight_to_100:\n",
    "            G.node[a]['weight'] = 100\n",
    "\n",
    "    # one-shot assigment: assign each node as it arrives\n",
    "    if restream_batches == 1:\n",
    "        alpha = one_shot_alpha\n",
    "        partition_votes = fennel.get_votes(G, a, num_partitions, assignments)\n",
    "        assignments[a] = fennel.get_assignment(G, a, num_partitions, assignments, partition_votes, alpha, 0)\n",
    "        fixed[a] = 1\n",
    "        nodes_arrived.append(a)\n",
    "\n",
    "        # make a subgraph of all arrived nodes\n",
    "        Gsub = G.subgraph(nodes_arrived)\n",
    "\n",
    "        x = shared.score(Gsub, assignments, num_partitions)\n",
    "        print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3:.10f}\".format(x[0], x[1], x[2], alpha))\n",
    "        continue\n",
    "\n",
    "    batch_arrived.append(a)\n",
    "\n",
    "    if restream_batches == len(batch_arrived):\n",
    "\n",
    "        # GRAPH MODIFICATION FUNCTIONS\n",
    "        if graph_modification_functions:\n",
    "\n",
    "            # set node weight to prediction generated from a GAM\n",
    "            if alter_node_weight_to_gam_prediction and len(total_arrived) >= 160: # XXX implement >=\n",
    "                total_arrived = nodes_arrived + batch_arrived + [a]\n",
    "                gam_weights = shared.gam_predict(POPULATION_LOCATION_FILE, len(total_arrived))\n",
    "\n",
    "                for node in G.nodes_iter():\n",
    "                    if alter_arrived_node_weight_to_100 and node in total_arrived:\n",
    "                        pass\n",
    "                    else:\n",
    "                        G.node[node]['weight'] = int(gam_weights[node] * 100)\n",
    "\n",
    "            G = edge_expansion(G)\n",
    "\n",
    "        # make a subgraph of all arrived nodes\n",
    "        Gsub = G.subgraph(nodes_arrived + batch_arrived)\n",
    "\n",
    "        # recalculate alpha\n",
    "        if Gsub.is_directed():\n",
    "            # as it's a directed graph, edges_arrived is actually double, so divide by 2\n",
    "            edges_arrived = Gsub.number_of_edges() / 2\n",
    "        else:\n",
    "            edges_arrived = Gsub.number_of_edges()\n",
    "        nodes_fixed = len([o for o in fixed if o == 1])\n",
    "        alpha = (edges_arrived) * (num_partitions / (nodes_fixed + len(batch_arrived))**2)\n",
    "\n",
    "        if alter_node_weight_to_gam_prediction:\n",
    "            # justification: the gam learns the entire population, so run fennal on entire population\n",
    "            assignments = fennel.generate_prediction_model(G,\n",
    "                                                           num_iterations,\n",
    "                                                           num_partitions,\n",
    "                                                           assignments,\n",
    "                                                           fixed,\n",
    "                                                           alpha)\n",
    "        else:\n",
    "            # use the information we have, those that arrived\n",
    "            assignments = fennel.generate_prediction_model(Gsub,\n",
    "                                                           num_iterations,\n",
    "                                                           num_partitions,\n",
    "                                                           assignments,\n",
    "                                                           fixed,\n",
    "                                                           alpha)\n",
    "\n",
    "\n",
    "        # assign nodes to prediction model\n",
    "        for n in batch_arrived:\n",
    "            fixed[n] = 1\n",
    "            nodes_arrived.append(n)\n",
    "\n",
    "        x = shared.score(Gsub, assignments, num_partitions)\n",
    "        print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3:.10f}\".format(x[0], x[1], x[2], alpha))\n",
    "        batch_arrived = []\n",
    "\n",
    "# remove nodes not fixed\n",
    "for i in range(0, len(assignments)):\n",
    "    if fixed[i] == -1:\n",
    "        assignments[i] = -1\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_virtual_nodes:\n",
    "    print(\"Remove virtual nodes\")\n",
    "    \n",
    "    print(\"\\nCurrent graph:\")\n",
    "    print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "    print(\"Edges: {}\".format(G.number_of_edges()))\n",
    "\n",
    "    G.remove_nodes_from(virtual_nodes)\n",
    "    assignments = np.delete(assignments, virtual_nodes)\n",
    "    fixed = np.delete(fixed, virtual_nodes)\n",
    "\n",
    "    print(\"\\nVirtual nodes removed:\")\n",
    "    print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "    print(\"Edges: {}\".format(G.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add partition attribute to nodes\n",
    "for i in range(0, len(assignments)):\n",
    "    G.add_nodes_from([i], partition=str(assignments[i]))\n",
    "\n",
    "# Remove original node/edge weights\n",
    "for node in G.nodes_iter(data=True):\n",
    "    if 'weight_orig' in node[1]:\n",
    "        del node[1]['weight_orig']\n",
    "for edge in G.edges_iter(data=True):\n",
    "    if 'weight_orig' in edge[2]:\n",
    "        del edge[2]['weight_orig']\n",
    "\n",
    "# Freeze Graph from further modification\n",
    "G = nx.freeze(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete graph with 1000 nodes\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-all-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-all-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-all-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-all-edges-oslom.txt\n",
      "\n",
      "Config\n",
      "-------\n",
      "\n",
      "file: 091137\n",
      "num_partitions: 4\n",
      "num_iterations: 10\n",
      "prediction_model_cut_off: 0.1\n",
      "one_shot_alpha: 0.5\n",
      "restream_batches: 10\n",
      "use_virtual_nodes: False\n",
      "virtual_edge_weight: 1.0\n",
      "\n",
      "Metrics\n",
      "-------\n",
      "\n",
      "edges_cut: 571\n",
      "waste: 0.03600000000000003\n",
      "cut_ratio: 0.19428376998979244\n",
      "communication_volume: 649\n",
      "network_permanence: 0.368160\n",
      "Q: -0.0012827457612951344\n",
      "NQ: -71.34113442306348\n",
      "Qds: -0.9999999999999944\n",
      "intraEdges: 0.0\n",
      "interEdges: 5.925403225806452\n",
      "intraDensity: 0.0\n",
      "modularity degree: -5878.0\n",
      "conductance: 1.0\n",
      "expansion: 5.925403225806452\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -1.3035186342505352E-9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%H%M%S')\n",
    "data_filename,_ = os.path.splitext(os.path.basename(DATA_FILENAME))\n",
    "data_filename += \"-\" + timestamp\n",
    "\n",
    "graph_metrics = {\n",
    "    \"file\": timestamp,\n",
    "    \"num_partitions\": num_partitions,\n",
    "    \"num_iterations\": num_iterations,\n",
    "    \"prediction_model_cut_off\": prediction_model_cut_off,\n",
    "    \"one_shot_alpha\": one_shot_alpha,\n",
    "    \"restream_batches\": restream_batches,\n",
    "    \"use_virtual_nodes\": use_virtual_nodes,\n",
    "    \"virtual_edge_weight\": virtual_edge_weight,\n",
    "}\n",
    "graph_fieldnames = [\n",
    "    \"file\",\n",
    "    \"num_partitions\",\n",
    "    \"num_iterations\",\n",
    "    \"prediction_model_cut_off\",\n",
    "    \"one_shot_alpha\",\n",
    "    \"restream_batches\",\n",
    "    \"use_virtual_nodes\",\n",
    "    \"virtual_edge_weight\",\n",
    "    \"edges_cut\",\n",
    "    \"waste\",\n",
    "    \"cut_ratio\",\n",
    "    \"communication_volume\",\n",
    "    \"network_permanence\",\n",
    "    \"Q\",\n",
    "    \"NQ\",\n",
    "    \"Qds\",\n",
    "    \"intraEdges\",\n",
    "    \"interEdges\",\n",
    "    \"intraDensity\",\n",
    "    \"modularity degree\",\n",
    "    \"conductance\",\n",
    "    \"expansion\",\n",
    "    \"contraction\",\n",
    "    \"fitness\",\n",
    "    \"QovL\",\n",
    "]\n",
    "\n",
    "print(\"Complete graph with {} nodes\".format(G.number_of_nodes()))\n",
    "(file_maxperm, file_oslom) = shared.write_graph_files(OUTPUT_DIRECTORY, \"{}-all\".format(data_filename), G)\n",
    "\n",
    "# original scoring algorithm\n",
    "scoring = shared.score(G, assignments, num_partitions)\n",
    "graph_metrics.update({\n",
    "    \"waste\": scoring[0],\n",
    "    \"cut_ratio\": scoring[1],\n",
    "})\n",
    "\n",
    "# edges cut and communication volume\n",
    "edges_cut, steps = shared.base_metrics(G)\n",
    "graph_metrics.update({\n",
    "    \"edges_cut\": edges_cut,\n",
    "    \"communication_volume\": steps,\n",
    "})\n",
    "\n",
    "# MaxPerm\n",
    "max_perm = shared.run_max_perm(file_maxperm)\n",
    "graph_metrics.update({\"network_permanence\": max_perm})\n",
    "\n",
    "# Community Quality metrics\n",
    "community_metrics = shared.run_community_metrics(OUTPUT_DIRECTORY,\n",
    "                                                 \"{}-all\".format(data_filename),\n",
    "                                                 file_oslom)\n",
    "graph_metrics.update(community_metrics)\n",
    "\n",
    "print(\"\\nConfig\")\n",
    "print(\"-------\\n\")\n",
    "for f in graph_fieldnames[:8]:\n",
    "    print(\"{}: {}\".format(f, graph_metrics[f]))\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\"-------\\n\")\n",
    "for f in graph_fieldnames[8:]:\n",
    "    print(\"{}: {}\".format(f, graph_metrics[f]))\n",
    "\n",
    "# write metrics to CSV\n",
    "metrics_filename = os.path.join(OUTPUT_DIRECTORY, \"metrics.csv\")\n",
    "shared.write_metrics_csv(metrics_filename, graph_fieldnames, graph_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Partition 0 with 245 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p0-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p0-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p0-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p0-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 091137\n",
      "partition: 0\n",
      "network_permanence: 1.000000\n",
      "Q: -0.005610837744881655\n",
      "NQ: -20.033273788121495\n",
      "Qds: -0.9999999999999989\n",
      "intraEdges: 0.0\n",
      "interEdges: 4.821576763485477\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1162.0\n",
      "conductance: 1.0\n",
      "expansion: 4.821576763485477\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -9.660366978670604E-8\n",
      "\n",
      "Partition 1 with 259 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p1-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p1-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p1-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p1-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 091137\n",
      "partition: 1\n",
      "network_permanence: 1.000000\n",
      "Q: -0.004898430286241912\n",
      "NQ: -19.361148453234367\n",
      "Qds: -1.0000000000000022\n",
      "intraEdges: 0.0\n",
      "interEdges: 4.56\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1140.0\n",
      "conductance: 1.0\n",
      "expansion: 4.56\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -7.837488457987087E-8\n",
      "\n",
      "Partition 2 with 250 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p2-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p2-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p2-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p2-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 091137\n",
      "partition: 2\n",
      "network_permanence: 1.000000\n",
      "Q: -0.005242362204348214\n",
      "NQ: -17.719579514210967\n",
      "Qds: -1.000000000000001\n",
      "intraEdges: 0.0\n",
      "interEdges: 5.238866396761134\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1294.0\n",
      "conductance: 1.0\n",
      "expansion: 5.238866396761134\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -8.592768615037472E-8\n",
      "\n",
      "Partition 3 with 246 nodes\n",
      "-----------------------------\n",
      "\n",
      "Writing GML file: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p3-graph.gml\n",
      "Writing assignments: /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p3-assignments.txt\n",
      "Writing edge list (for MaxPerm): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p3-edges-maxperm.txt\n",
      "Writing edge list (for OSLOM): /home/sami/repos/smbwebs/graph-partitioning/output/oneshot_fennel_weights-091137-p3-edges-oslom.txt\n",
      "\n",
      "Metrics\n",
      "file: 091137\n",
      "partition: 3\n",
      "network_permanence: 1.000000\n",
      "Q: -0.005600184672206818\n",
      "NQ: -20.54672696366759\n",
      "Qds: -1.000000000000002\n",
      "intraEdges: 0.0\n",
      "interEdges: 4.7899159663865545\n",
      "intraDensity: 0.0\n",
      "modularity degree: -1140.0\n",
      "conductance: 1.0\n",
      "expansion: 4.7899159663865545\n",
      "contraction: 0.0\n",
      "fitness: 0.0\n",
      "QovL: -9.88663348670086E-8\n"
     ]
    }
   ],
   "source": [
    "partition_metrics = {}\n",
    "partition_fieldnames = [\n",
    "    \"file\",\n",
    "    \"partition\",\n",
    "    \"network_permanence\",\n",
    "    \"Q\",\n",
    "    \"NQ\",\n",
    "    \"Qds\",\n",
    "    \"intraEdges\",\n",
    "    \"interEdges\",\n",
    "    \"intraDensity\",\n",
    "    \"modularity degree\",\n",
    "    \"conductance\",\n",
    "    \"expansion\",\n",
    "    \"contraction\",\n",
    "    \"fitness\",\n",
    "    \"QovL\",\n",
    "]\n",
    "\n",
    "for p in range(0, num_partitions):\n",
    "    partition_metrics = {\n",
    "        \"file\": timestamp,\n",
    "        \"partition\": p\n",
    "    }\n",
    "\n",
    "    nodes = [i for i,x in enumerate(assignments) if x == p]\n",
    "    Gsub = G.subgraph(nodes)\n",
    "    print(\"\\nPartition {} with {} nodes\".format(p, Gsub.number_of_nodes()))\n",
    "    print(\"-----------------------------\\n\")\n",
    "\n",
    "    (file_maxperm, file_oslom) = shared.write_graph_files(OUTPUT_DIRECTORY, \"{}-p{}\".format(data_filename, p), Gsub)\n",
    "    \n",
    "    # MaxPerm\n",
    "    max_perm = shared.run_max_perm(file_maxperm)\n",
    "    partition_metrics.update({\"network_permanence\": max_perm})\n",
    "\n",
    "    # Community Quality metrics\n",
    "    community_metrics = shared.run_community_metrics(OUTPUT_DIRECTORY,\n",
    "                                                     \"{}-p{}\".format(data_filename, p),\n",
    "                                                     file_oslom)\n",
    "    partition_metrics.update(community_metrics)\n",
    "\n",
    "    print(\"\\nMetrics\")\n",
    "    for f in partition_fieldnames:\n",
    "        print(\"{}: {}\".format(f, partition_metrics[f]))\n",
    "\n",
    "    # write metrics to CSV\n",
    "    metrics_filename = os.path.join(OUTPUT_DIRECTORY, \"metrics-partitions.csv\")\n",
    "    shared.write_metrics_csv(metrics_filename, partition_fieldnames, partition_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
