{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOTCH Environment valid.\n",
      "SCOTCH python bindings were loaded correctly from ../csap-graphpartitioning/src/python \n",
      "SCOTCH Library was located successfully at ../csap-graphpartitioning/tools/scotch/lib/macOS/libscotch.dylib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shared\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import pyximport; pyximport.install()\n",
    "import fennel\n",
    "\n",
    "# ******** SECTION 1 ************* #\n",
    "\n",
    "try:\n",
    "    import config\n",
    "except ImportError as err:\n",
    "    print(err)\n",
    "    print(\"**Could not load config.py\\n**Copy config_template.py and rename it.\")\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "DATA_FILENAME = os.path.join(pwd, \"data\", \"oneshot_fennel_weights.txt\")\n",
    "OUTPUT_DIRECTORY = os.path.join(pwd, \"output\")\n",
    "\n",
    "# Read input file for prediction model, if not provided a prediction\n",
    "# model is made using FENNEL\n",
    "PREDICTION_MODEL = \"\"\n",
    "\n",
    "# File containing simulated arrivals. This is used in simulating nodes\n",
    "# arriving at the shelter. Nodes represented by line number; value of\n",
    "# 1 represents a node as arrived; value of 0 represents the node as not\n",
    "# arrived or needing a shelter.\n",
    "SIMULATED_ARRIVAL_FILE = os.path.join(pwd, \"data\", \"simulated_arrival.txt\")\n",
    "#SIMULATED_ARRIVAL_FILE = \"\"\n",
    "\n",
    "# File containing the geographic location of each node.\n",
    "POPULATION_LOCATION_FILE = os.path.join(pwd, \"data\", \"population_location.csv\")\n",
    "\n",
    "# Number of shelters\n",
    "num_partitions = 4\n",
    "\n",
    "# The number of iterations when making prediction model\n",
    "num_iterations = 10\n",
    "\n",
    "# Percentage of prediction model to use before discarding\n",
    "# When set to 0, prediction model is discarded, useful for one-shot\n",
    "prediction_model_cut_off = 0.10\n",
    "\n",
    "# Alpha value used in one-shot (when restream_batches set to 1)\n",
    "one_shot_alpha = 0.5\n",
    "\n",
    "# Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "# When set to 1, one-shot is used with alpha value from above\n",
    "restream_batches = 10\n",
    "\n",
    "# Create virtual nodes based on prediction model\n",
    "use_virtual_nodes = False\n",
    "\n",
    "# Virtual nodes: edge weight\n",
    "virtual_edge_weight = 1.0\n",
    "\n",
    "\n",
    "####\n",
    "# GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "# Also enables the edge calculation function.\n",
    "graph_modification_functions = True\n",
    "\n",
    "# If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "# otherwise the node is removed from the graph.\n",
    "alter_arrived_node_weight_to_100 = True\n",
    "\n",
    "# Uses generalized additive models from R to generate prediction of nodes not\n",
    "# arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "# given by a GAM.\n",
    "# Needs POPULATION_LOCATION_FILE to be set.\n",
    "alter_node_weight_to_gam_prediction = True\n",
    "\n",
    "gam_k_value = 100\n",
    "\n",
    "# Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "# de-emphasise the prediction model for the unknown nodes.\n",
    "prediction_model_emphasis = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded...\n",
      "Nodes: 1000\n",
      "Edges: 2939\n",
      "Graph is undirected\n"
     ]
    }
   ],
   "source": [
    "# read METIS file\n",
    "G = shared.read_metis(DATA_FILENAME)\n",
    "\n",
    "# Alpha value used in prediction model\n",
    "prediction_model_alpha = G.number_of_edges() * (num_partitions / G.number_of_nodes()**2)\n",
    "\n",
    "# Order of nodes arriving\n",
    "arrival_order = list(range(0, G.number_of_nodes()))\n",
    "\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(arrival_order)\n",
    "\n",
    "if SIMULATED_ARRIVAL_FILE == \"\":\n",
    "    # mark all nodes as needing a shelter\n",
    "    simulated_arrival_list = [1]*G.number_of_nodes()\n",
    "else:\n",
    "    with open(SIMULATED_ARRIVAL_FILE, \"r\") as ar:\n",
    "        simulated_arrival_list = [int(line.rstrip('\\n')) for line in ar]\n",
    "\n",
    "print(\"Graph loaded...\")\n",
    "print(\"Nodes: {}\".format(G.number_of_nodes()))\n",
    "print(\"Edges: {}\".format(G.number_of_edges()))\n",
    "if nx.is_directed(G):\n",
    "    print(\"Graph is directed\")\n",
    "else:\n",
    "    print(\"Graph is undirected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION MODEL\n",
      "----------------\n",
      "Using: SCOTCH Partitioning\n",
      "--------------------------\n",
      "\n",
      "WASTE\t\tCUT RATIO\tEDGES CUT\tCOMM VOLUME\n",
      "0.05200\t\t0.0214358625\t63\t\t107\n",
      "\n",
      "Assignments:\n",
      "[ 3  1  2  0  0  0  0  2  3  1  3  1  0  1  1  0  3  2  0  0  1  2  3  2  1  3  2  3  0  1  0  2  0  3  3  0  1  3  2  1  2  1  3  1  1  2  1  3  3  2  0  3  3  2  3  2  0  0  1  0  2  0  1  2  1  1  3  2  1  3  1  0  0  1  3  2  0  3  3  0  2  3  0  2  1  3  1  0  1  0  0  3  3  0  0  2  3  2  1  3  1  0  2  0  1  1  1  0  1  3  2  0  2  3  0  1  3  1  0  2  1  1  0  0  0  3  0  2  0  1  0  3  1  3  3  1  1  2  3  3  1  2  2  0  2  1  3  2  0  3  0  1  1  0  1  2  1  2  3  0  1  1  0  0  1  3  1  3  3  1  3  1  2  3  2  1  1  0  0  1  2  0  1  2  3  1  2  1  0  2  3  2  3  0  0  1  3  0  1  0  2  3  3  1  0  2  2  1  0  2  3  3  3  0  0  0  2  0  2  2  1  1  1  1  2  2  2  0  0  0  1  2  3  3  3  1  3  0  0  1  2  2  0  3  3  2  2  1  0  1  1  3  0  3  3  3  3  2  3  0  3  3  0  2  3  1  0  2  2  3  3  3  1  3  1  2  0  1  2  1  2  3  3  2  1  1  0  2  0  0  0  1  0  1  2  3  2  0  3  1  0  0  3  2  1  0  1  2  1  1  2  2  0  2  3  0  3  0  1  1  0  1  0  1  2  3  3  1  0  0  2  3  3  3  0  0  3  1  3  0  3  1  2  2  3  2  1  1  1  2  1  2  3  3  2  0  0  2  3  1  1  2  2  1  0  1  2  1  0  2  0  3  3  3  2  3  3  2  0  3  3  2  3  0  0  3  2  0  3  1  1  3  2  3  2  3  0  0  0  3  1  3  0  0  0  1  0  3  0  2  1  0  1  0  3  0  2  2  0  0  3  0  1  3  1  3  1  3  1  3  2  0  1  0  1  2  3  0  3  1  3  0  2  3  0  2  0  0  1  2  1  3  2  3  2  0  2  2  1  3  1  3  1  3  2  2  0  0  0  3  2  1  1  0  3  3  3  3  2  2  2  2  0  3  3  3  1  1  0  1  3  1  0  2  0  2  3  3  0  1  3  2  3  3  3  1  3  1  3  0  3  2  3  1  3  3  1  3  1  1  3  0  0  1  2  3  2  2  3  1  1  2  2  2  1  1  0  3  1  2  3  2  1  2  2  2  2  1  2  0  0  1  1  0  0  0  1  3  2  2  3  0  1  0  3  3  3  2  0  3  2  2  3  0  1  1  2  0  3  1  1  2  2  0  3  2  2  0  2  1  2  2  3  3  2  2  1  2  0  3  2  1  0  1  0  3  3  1  2  0  1  3  0  0  3  0  1  0  0  1  2  0  2  0  2  3  1  0  2  1  1  3  2  3  3  0  3  1  1  1  0  3  3  0  1  0  1  2  2  0  3  2  1  0  3  0  2  1  2  1  1  2  3  2  0  3  0  1  0  2  0  0  1  1  3  0  0  2  1  0  2  1  2  1  1  3  2  2  3  3  1  1  2  2  2  2  0  1  0  0  1  3  3  1  0  1  1  1  3  3  3  1  3  0  1  1  0  0  0  0  2  0  1  3  3  3  0  2  2  0  0  1  2  1  3  3  2  2  2  3  2  2  2  1  3  1  0  1  0  0  1  2  3  1  0  1  2  2  1  0  0  2  1  0  3  2  3  0  3  3  2  1  0  2  1  3  1  3  1  0  1  0  0  3  0  3  1  2  0  0  3  0  0  2  3  0  3  1  1  3  3  2  2  1  3  3  0  2  0  2  2  0  2  1  1  3  3  0  3  1  1  1  0  1  2  0  0  3  3  3  2  3  0  3  2  3  2  1  1  2  1  0  0  2  1  1  1  1  1  2  3  0  3  3  3  2  1  0  1  2  1  0  0  1  1  0  1  0  1  0  0  1  0  0  1  0  0  0  1  1  2  0  2  0  1  0  1  0  2  2  0  1  2  1  3  0  0  3  3  3  2  2  0  1  2  0  1  2  2  3  1  2  3  0  1  1  2  2  0  2  3  1  0  3  1  2  0  3  2  1  0  1  0  3  0  0  0  0  0  2  1  2  3  3  1  1  3  3  3  2  1  2  2  0  1  2  1  0  1  0  2  1  0  1  0  1  1  2  0  0  0  3  2  0  1  1  1  3  2  0  0  0  2  1  3  3  3  0  1  1  3  2  3  3  3  1  2  1  0  1]\n",
      "\n",
      "Fixed: 0\n",
      "\n",
      "Partitions - nodes (weight):\n",
      "P0: 262.0 (262)\n",
      "P1: 263.0 (263)\n",
      "P2: 229.0 (229)\n",
      "P3: 246.0 (246)\n"
     ]
    }
   ],
   "source": [
    "# setup for other algorithms\n",
    "if config.ENABLE_SCOTCH == True:\n",
    "    # import the relevant SCOTCH modules\n",
    "    from scotch.graph_mapper import GraphMapper\n",
    "    from scotch.io import ScotchGraphArrays\n",
    "\n",
    "UNMAPPED = -1\n",
    "\n",
    "# reset\n",
    "assignments = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "fixed = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "\n",
    "print(\"PREDICTION MODEL\")\n",
    "print(\"----------------\")\n",
    "\n",
    "# Display which algorithm is being run\n",
    "if config.PREDICTION_MODEL_ALGORITHM == config.Partitioners.FENNEL:\n",
    "    print(\"Using: FENNEL Partitioning\")\n",
    "    print(\"---------------\\n\")\n",
    "elif config.PREDICTION_MODEL_ALGORITHM == config.Partitioners.SCOTCH:\n",
    "    print(\"Using: SCOTCH Partitioning\")\n",
    "    print(\"--------------------------\\n\")\n",
    "\n",
    "predictionModels = {}\n",
    "# store model data for different types of partitioners\n",
    "# NOTE: THIS IS NOT IMPLEMENTED YET - need to discuss first\n",
    "if config.RUN_ALL_PREDICTION_MODEL_ALGORITHMS == True:\n",
    "    # create different prediction models\n",
    "    fennelModel = {}\n",
    "    fennelModel['assignments'] = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "    fennelModel['fixed'] = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "\n",
    "    predictionModels[config.Partitioners.FENNEL] = fennelModel\n",
    "\n",
    "    scotchModel = {}\n",
    "    scotchModel['assignments'] = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "    scotchModel['fixed'] = np.repeat(np.int32(UNMAPPED), G.number_of_nodes())\n",
    "\n",
    "    predictionModels[config.Partitioners.SCOTCH] = scotchModel\n",
    "\n",
    "# Begin computation of prediction model\n",
    "if PREDICTION_MODEL:\n",
    "    # if we have a prediction model from file, load it\n",
    "    with open(PREDICTION_MODEL, \"r\") as inf:\n",
    "        assignments = np.fromiter(inf.readlines(), dtype=np.int32)\n",
    "\n",
    "else:\n",
    "    # choose the right algorithm\n",
    "    if config.PREDICTION_MODEL_ALGORITHM == config.Partitioners.FENNEL:\n",
    "        assignments = fennel.generate_prediction_model(G, num_iterations, num_partitions, assignments, fixed, prediction_model_alpha)\n",
    "    elif config.PREDICTION_MODEL_ALGORITHM == config.Partitioners.SCOTCH:\n",
    "        # SCOTCH algorithm\n",
    "        # we have a networkx graph already, G\n",
    "        scotchArrays = ScotchGraphArrays() # create the object storing all the SCOTCH arrays\n",
    "        scotchArrays.fromNetworkxGraph(G, baseval=0) # populate arrays from G\n",
    "\n",
    "        #scotchArrays.debugPrint() # uncomment this to print out contents of scotchArrays\n",
    "\n",
    "        # create instance of SCOTCH Library\n",
    "        mapper = GraphMapper(config.SCOTCH_LIB_PATH)\n",
    "\n",
    "        # set some optional parameters for the SCOTCH_Arch, SCOTCH_Strat, SCOTCH_Graph\n",
    "        # see csap-graphpartitioning/src/python/scotch/graph_mapper: GraphMapper.__init__() method for more options\n",
    "        mapper.kbalval = 0.1\n",
    "        mapper.numPartitions = num_partitions\n",
    "\n",
    "        # intializes the SCOTCH_Arch, SCOTCH_Strat, SCOTCH_Graph using scotchArray and optional parameters\n",
    "        ok = mapper.initialize(scotchArrays, verbose=False)\n",
    "        if(ok):\n",
    "            # we can proceed with graphMap, the data structures were setup correctly\n",
    "            ok = mapper.graphMap()\n",
    "            if(ok):\n",
    "                # graphMap was run successfully, copy the assignments\n",
    "                # make a deep copy as we then delete the mapper data, to clear memory\n",
    "                # and the array reference may be lost\n",
    "                assignments = np.array(mapper.scotchData._parttab, copy=True)\n",
    "\n",
    "                mapper.delObjects()\n",
    "            else:\n",
    "                print('Error while running graphMap()')\n",
    "        else:\n",
    "            print('Error while setting up SCOTCH for partitioning.')\n",
    "\n",
    "x = shared.score(G, assignments, num_partitions)\n",
    "edges_cut, steps = shared.base_metrics(G, assignments)\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tEDGES CUT\\tCOMM VOLUME\")\n",
    "print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\".format(x[0], x[1], edges_cut, steps))\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Virtual Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_virtual_nodes:\n",
    "    print(\"Creating virtual nodes and assigning edges based on prediction model\")\n",
    "\n",
    "    # create virtual nodes\n",
    "    virtual_nodes = list(range(G.number_of_nodes(), G.number_of_nodes() + num_partitions))\n",
    "    print(\"\\nVirtual nodes:\")\n",
    "\n",
    "    # create virtual edges\n",
    "    virtual_edges = []\n",
    "    for n in range(0, G.number_of_nodes()):\n",
    "        virtual_edges += [(n, virtual_nodes[assignments[n]])]\n",
    "\n",
    "    # extend assignments\n",
    "    assignments = np.append(assignments, np.array(list(range(0, num_partitions)), dtype=np.int32))\n",
    "    fixed = np.append(fixed, np.array([1] * num_partitions, dtype=np.int32))\n",
    "\n",
    "    G.add_nodes_from(virtual_nodes, weight=1)\n",
    "    G.add_edges_from(virtual_edges, weight=virtual_edge_weight)\n",
    "\n",
    "    print(\"\\nAssignments:\")\n",
    "    shared.fixed_width_print(assignments)\n",
    "    print(\"Last {} nodes are virtual nodes.\".format(num_partitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix the first batch of arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign first 100 arrivals using prediction model, then discard\n",
      "\n",
      "WASTE\t\tCUT RATIO\tEDGES CUT\tCOMM VOLUME\n",
      "8.00000\t\t0.1687648860\t496\t\t459\n",
      "\n",
      "Assignments:\n",
      "[-1  1  2  0 -1  0  0 -1 -1 -1  3 -1  0  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  0 -1 -1  2 -1  3 -1 -1  1 -1 -1  1 -1  1 -1  1 -1  2  1 -1  3  2  0 -1 -1 -1 -1  2  0 -1  1  0 -1 -1 -1 -1  1 -1  3  2  1  3  1 -1 -1 -1 -1 -1  0 -1 -1  0 -1 -1 -1 -1  1 -1  1 -1 -1  0  0  3 -1  0  0 -1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1  0 -1  3 -1  0 -1 -1 -1  1  3  1 -1 -1  1 -1  0  0 -1  3 -1 -1  0  1  0 -1  1 -1 -1 -1  1 -1  3  3  1  2  2 -1 -1  1 -1  2 -1 -1 -1 -1  1  0  1  2  1 -1 -1 -1  1  1  0 -1  1  3  1  3 -1 -1 -1  1 -1  3 -1  1 -1 -1 -1  1 -1  0 -1 -1  3  1 -1  1 -1 -1 -1 -1 -1 -1  0  1 -1 -1  1  0 -1 -1 -1  1  0 -1 -1  1 -1 -1 -1 -1  3  0 -1  0 -1  0 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "\n",
      "Fixed: 100\n",
      "\n",
      "Partitions - nodes:\n",
      "P0: 29\n",
      "P1: 45\n",
      "P2: 10\n",
      "P3: 16\n"
     ]
    }
   ],
   "source": [
    "cut_off_value = int(prediction_model_cut_off * G.number_of_nodes())\n",
    "if prediction_model_cut_off == 0:\n",
    "    print(\"Discarding prediction model\\n\")\n",
    "else:\n",
    "    print(\"Assign first {} arrivals using prediction model, then discard\\n\".format(cut_off_value))\n",
    "\n",
    "# fix arrivals\n",
    "nodes_arrived = []\n",
    "for a in arrival_order:\n",
    "    # check if node needs a shelter\n",
    "    if simulated_arrival_list[a] == 0:\n",
    "        continue\n",
    "\n",
    "    # set 100% node weight for those that need a shelter\n",
    "    if alter_arrived_node_weight_to_100:\n",
    "        G.node[a]['weight'] = 100\n",
    "\n",
    "    nodes_fixed = len([o for o in fixed if o == 1])\n",
    "    if nodes_fixed >= cut_off_value:\n",
    "        break\n",
    "    fixed[a] = 1\n",
    "    nodes_arrived.append(a)\n",
    "\n",
    "# remove nodes not fixed, ie. discard prediction model\n",
    "for i in range(0, len(assignments)):\n",
    "    if fixed[i] == -1:\n",
    "        assignments[i] = -1\n",
    "\n",
    "x = shared.score(G, assignments, num_partitions)\n",
    "edges_cut, steps = shared.base_metrics(G, assignments)\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tEDGES CUT\\tCOMM VOLUME\")\n",
    "print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\".format(x[0], x[1], edges_cut, steps))\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Batch Arrival Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning in batches of 10\n",
      "--------------------------------\n",
      "\n",
      "Graph mod fncs: True\n",
      "restream_batches: 10\n",
      "WASTE\t\tCUT RATIO\tEDGES CUT\tCOMM VOLUME\tALPHA\n",
      "Removing Node 0\n",
      "Removing Node 4\n",
      "Removing Node 7\n",
      "Removing Node 8\n",
      "Removing Node 9\n",
      "Removing Node 11\n",
      "Removing Node 14\n",
      "Removing Node 15\n",
      "Removing Node 16\n",
      "Removing Node 17\n",
      "Removing Node 18\n",
      "Removing Node 19\n",
      "Removing Node 21\n",
      "Removing Node 22\n",
      "Removing Node 23\n",
      "Removing Node 25\n",
      "Removing Node 26\n",
      "Removing Node 27\n",
      "Removing Node 29\n",
      "Removing Node 30\n",
      "Removing Node 32\n",
      "Removing Node 34\n",
      "Removing Node 35\n",
      "Removing Node 37\n",
      "Removing Node 38\n",
      "Removing Node 40\n",
      "Removing Node 42\n",
      "Removing Node 44\n",
      "Removing Node 47\n",
      "Removing Node 51\n",
      "Removing Node 52\n",
      "Removing Node 53\n",
      "Removing Node 54\n",
      "Removing Node 57\n",
      "Removing Node 60\n",
      "Removing Node 61\n",
      "Removing Node 62\n",
      "Removing Node 63\n",
      "Removing Node 65\n",
      "Removing Node 71\n",
      "Removing Node 72\n",
      "Removing Node 73\n",
      "Removing Node 74\n",
      "Removing Node 75\n",
      "Removing Node 77\n",
      "Removing Node 78\n",
      "Removing Node 80\n",
      "Removing Node 81\n",
      "Removing Node 82\n",
      "Removing Node 83\n",
      "Removing Node 85\n",
      "Removing Node 87\n",
      "Removing Node 88\n",
      "Removing Node 92\n",
      "Removing Node 95\n",
      "Removing Node 96\n",
      "Removing Node 97\n",
      "Removing Node 99\n",
      "Removing Node 101\n",
      "Removing Node 102\n",
      "Removing Node 103\n",
      "Removing Node 104\n",
      "Removing Node 106\n",
      "Removing Node 108\n",
      "Removing Node 110\n",
      "Removing Node 112\n",
      "Removing Node 113\n",
      "Removing Node 114\n",
      "Removing Node 118\n",
      "Removing Node 119\n",
      "Removing Node 121\n",
      "Removing Node 124\n",
      "Removing Node 126\n",
      "Removing Node 127\n",
      "Removing Node 131\n",
      "Removing Node 133\n",
      "Removing Node 134\n",
      "Removing Node 135\n",
      "Removing Node 137\n",
      "Removing Node 143\n",
      "Removing Node 144\n",
      "Removing Node 146\n",
      "Removing Node 148\n",
      "Removing Node 149\n",
      "Removing Node 150\n",
      "Removing Node 151\n",
      "Removing Node 157\n",
      "Removing Node 158\n",
      "Removing Node 159\n",
      "Removing Node 163\n",
      "Removing Node 168\n",
      "Removing Node 169\n",
      "Removing Node 170\n",
      "Removing Node 172\n",
      "Removing Node 174\n",
      "Removing Node 176\n",
      "Removing Node 177\n",
      "Removing Node 178\n",
      "Removing Node 180\n",
      "Removing Node 182\n",
      "Removing Node 183\n",
      "Removing Node 186\n",
      "Removing Node 188\n",
      "Removing Node 189\n",
      "Removing Node 190\n",
      "Removing Node 191\n",
      "Removing Node 192\n",
      "Removing Node 193\n",
      "Removing Node 196\n",
      "Removing Node 197\n",
      "Removing Node 200\n",
      "Removing Node 201\n",
      "Removing Node 202\n",
      "Removing Node 205\n",
      "Removing Node 206\n",
      "Removing Node 208\n",
      "Removing Node 209\n",
      "Removing Node 210\n",
      "Removing Node 211\n",
      "Removing Node 214\n",
      "Removing Node 216\n",
      "Removing Node 218\n",
      "Removing Node 219\n",
      "Setting weight=100 on node 223\n",
      "7.89100\t\t0.0454545455\t2\t\t4\t\t0.0145454545\n",
      "7.88100\t\t0.0638297872\t3\t\t6\t\t0.0130555556\n",
      "7.87100\t\t0.1607142857\t9\t\t16\t\t0.0132544379\n",
      "7.86100\t\t0.1935483871\t12\t\t21\t\t0.0126530612\n"
     ]
    }
   ],
   "source": [
    "if restream_batches == 1:\n",
    "    print(\"One-shot assignment mode\")\n",
    "    print(\"------------------------\\n\")\n",
    "else:\n",
    "    print(\"Assigning in batches of {}\".format(restream_batches))\n",
    "    print(\"--------------------------------\\n\")\n",
    "\n",
    "def edge_expansion(G):\n",
    "    # Update edge weights for nodes that have an assigned probability of displacement\n",
    "    for edge in G.edges_iter(data=True):\n",
    "        left = edge[0]\n",
    "        right = edge[1]\n",
    "        edge_weight = edge[2]['weight_orig']\n",
    "\n",
    "        # new edge weight\n",
    "        edge[2]['weight'] = (float(G.node[left]['weight']) * edge_weight) * (float(G.node[right]['weight']) * edge_weight)\n",
    "\n",
    "        if left in nodes_arrived or right in nodes_arrived:\n",
    "            # change the emphasis of the prediction model\n",
    "            edge[2]['weight'] = edge[2]['weight'] * prediction_model_emphasis\n",
    "\n",
    "    return G\n",
    "\n",
    "# preserve original node/edge weight\n",
    "if graph_modification_functions:\n",
    "    node_weights = {n[0]: n[1]['weight'] for n in G.nodes_iter(data=True)}\n",
    "    nx.set_node_attributes(G, 'weight_orig', node_weights)\n",
    "\n",
    "    edge_weights = {(e[0], e[1]): e[2]['weight'] for e in G.edges_iter(data=True)}\n",
    "    nx.set_edge_attributes(G, 'weight_orig', edge_weights)\n",
    "\n",
    "\n",
    "# SETUP SCOTCH VARIABLES\n",
    "scotchMapper = None\n",
    "scotchArrayData = None\n",
    "if config.ASSIGNMENT_MODEL_ALGORITHM == config.Partitioners.SCOTCH:\n",
    "    scotchMapper = GraphMapper(config.SCOTCH_LIB_PATH, numPartitions=num_partitions)\n",
    "    scotchArrayData = ScotchGraphArrays()\n",
    "\n",
    "# FOR DEBUGGING PURPOSES:\n",
    "print('Graph mod fncs:',graph_modification_functions)\n",
    "print('restream_batches:', restream_batches)\n",
    "\n",
    "batch_arrived = []\n",
    "print(\"WASTE\\t\\tCUT RATIO\\tEDGES CUT\\tCOMM VOLUME\\tALPHA\")\n",
    "for i, a in enumerate(arrival_order):\n",
    "\n",
    "    # check if node is already arrived\n",
    "    if fixed[a] == 1:\n",
    "        continue\n",
    "\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "    if graph_modification_functions:\n",
    "\n",
    "        # remove nodes that don't need a shelter\n",
    "        if simulated_arrival_list[a] == 0:\n",
    "            print('Removing Node', a)\n",
    "            G.remove_node(a)\n",
    "            continue\n",
    "\n",
    "        # set 100% node weight for those that need a shelter\n",
    "        if alter_arrived_node_weight_to_100:\n",
    "            print(\"Setting weight=100 on node\", a)\n",
    "            G.node[a]['weight'] = 100\n",
    "\n",
    "    # one-shot assigment: assign each node as it arrives\n",
    "    if restream_batches == 1:\n",
    "        alpha = one_shot_alpha\n",
    "\n",
    "        if config.ASSIGNMENT_MODEL_ALGORITHM == config.Partitioners.FENNEL:\n",
    "            partition_votes = fennel.get_votes(G, a, num_partitions, assignments)\n",
    "            assignments[a] = fennel.get_assignment(G, a, num_partitions, assignments, partition_votes, alpha, 0)\n",
    "        elif config.ASSIGNMENT_MODEL_ALGORITHM == config.Partitioners.SCOTCH:\n",
    "            # load array data from graph\n",
    "            scotchArrayData.fromNetworkxGraph(G, parttab=assignments)\n",
    "            ok = scotchMapper.initialize(scotchArrayData)\n",
    "            if(ok):\n",
    "                # mapper initialized\n",
    "                ok = scotchMapper.graphMapFixed()\n",
    "                if(ok):\n",
    "                    assignments = scotchMapper.scotchData._parttab\n",
    "                else:\n",
    "                    print(\"Error running graphMapFixed()\")\n",
    "            else:\n",
    "                print(\"Error initializing SCOTCH GraphMapper for graphMapFixed()\")\n",
    "        fixed[a] = 1\n",
    "        nodes_arrived.append(a)\n",
    "\n",
    "        # make a subgraph of all arrived nodes\n",
    "        Gsub = G.subgraph(nodes_arrived)\n",
    "\n",
    "        x = shared.score(Gsub, assignments, num_partitions)\n",
    "        edges_cut, steps = shared.base_metrics(Gsub, assignments)\n",
    "        print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\\t\\t{4:.10f}\".format(x[0], x[1], edges_cut, steps, alpha))\n",
    "        continue\n",
    "\n",
    "    batch_arrived.append(a)\n",
    "\n",
    "    # NOTE: TEMPORARY -> enable graph_modification_functions\n",
    "    graph_modification_functions = False\n",
    "\n",
    "    if restream_batches == len(batch_arrived) or i == len(arrival_order) - 1:\n",
    "\n",
    "        # GRAPH MODIFICATION FUNCTIONS\n",
    "        if graph_modification_functions:\n",
    "\n",
    "            # set node weight to prediction generated from a GAM\n",
    "            if alter_node_weight_to_gam_prediction:\n",
    "                total_arrived = nodes_arrived + batch_arrived + [a]\n",
    "                if len(total_arrived) < gam_k_value:\n",
    "                    k = len(total_arrived)\n",
    "                else:\n",
    "                    k = gam_k_value\n",
    "\n",
    "                gam_weights = shared.gam_predict(POPULATION_LOCATION_FILE, len(total_arrived), k)\n",
    "\n",
    "                for node in G.nodes_iter():\n",
    "                    if alter_arrived_node_weight_to_100 and node in total_arrived:\n",
    "                        pass # weight would have been set previously\n",
    "                    else:\n",
    "                        G.node[node]['weight'] = int(gam_weights[node] * 100)\n",
    "\n",
    "            G = edge_expansion(G)\n",
    "\n",
    "        # make a subgraph of all arrived nodes\n",
    "        Gsub = G.subgraph(nodes_arrived + batch_arrived)\n",
    "\n",
    "        # recalculate alpha\n",
    "        if Gsub.is_directed():\n",
    "            # as it's a directed graph, edges_arrived is actually double, so divide by 2\n",
    "            edges_arrived = Gsub.number_of_edges() / 2\n",
    "        else:\n",
    "            edges_arrived = Gsub.number_of_edges()\n",
    "        nodes_fixed = len([o for o in fixed if o == 1])\n",
    "        alpha = (edges_arrived) * (num_partitions / (nodes_fixed + len(batch_arrived))**2)\n",
    "\n",
    "        if alter_node_weight_to_gam_prediction:\n",
    "            # justification: the gam learns the entire population, so run fennal on entire population\n",
    "            assignments = fennel.generate_prediction_model(G,\n",
    "                                                           num_iterations,\n",
    "                                                           num_partitions,\n",
    "                                                           assignments,\n",
    "                                                           fixed,\n",
    "                                                           alpha)\n",
    "        else:\n",
    "            # use the information we have, those that arrived\n",
    "            assignments = fennel.generate_prediction_model(Gsub,\n",
    "                                                           num_iterations,\n",
    "                                                           num_partitions,\n",
    "                                                           assignments,\n",
    "                                                           fixed,\n",
    "                                                           alpha)\n",
    "\n",
    "\n",
    "        # assign nodes to prediction model\n",
    "        for n in batch_arrived:\n",
    "            fixed[n] = 1\n",
    "            nodes_arrived.append(n)\n",
    "\n",
    "        x = shared.score(Gsub, assignments, num_partitions)\n",
    "        edges_cut, steps = shared.base_metrics(Gsub, assignments)\n",
    "        print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\\t\\t{4:.10f}\".format(x[0], x[1], edges_cut, steps, alpha))\n",
    "        batch_arrived = []\n",
    "\n",
    "# remove nodes not fixed\n",
    "for i in range(0, len(assignments)):\n",
    "    if fixed[i] == -1:\n",
    "        assignments[i] = -1\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "shared.fixed_width_print(assignments)\n",
    "\n",
    "nodes_fixed = len([o for o in fixed if o == 1])\n",
    "print(\"\\nFixed: {}\".format(nodes_fixed))\n",
    "\n",
    "shared.print_partitions(G, assignments, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
